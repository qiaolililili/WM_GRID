{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as op\n",
    "import os\n",
    "# import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from fpdf import FPDF  \n",
    "\n",
    "import mne\n",
    "from mne.preprocessing import find_bad_channels_maxwell\n",
    "import matplotlib.pyplot as plt\n",
    "# from mne.time_frequency import psd_multitaper\n",
    "from mne.preprocessing import annotate_muscle_zscore\n",
    "from mne.preprocessing import ICA\n",
    "from mne.preprocessing import read_ica\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path =  'D:\\projects\\WM_GRID\\DATA\\mg99a'\n",
    "cal_path = 'D:\\projects\\WM_GRID\\DATA\\ctc'\n",
    "sss_path = 'D:\\projects\\WM_GRID\\DATA\\sss'\n",
    "\n",
    "# data_path =  '/data/pt_02783/memory_grid/rawdir/mg99a'\n",
    "# cal_path = 'data/pt_02783/ctc'\n",
    "# sss_path = 'data/pt_02783/sss'\n",
    "\n",
    "\n",
    "subject_list = ['mg99']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load config.py\n",
    "\"\"\"\n",
    "===========\n",
    "Config file\n",
    "===========\n",
    "\n",
    "Configurate the parameters of the study.\n",
    "\"\"\"\n",
    "for subject_id in subject_list[:1]:\n",
    "\n",
    "    # =============================================================================\n",
    "    # SESSION-SPECIFIC SETTINGS\n",
    "    # =============================================================================\n",
    "\n",
    "    # Set filename based on experiment number\n",
    "\n",
    "    file_exts = ['%sa01',\n",
    "                     '%sa02',\n",
    "                     '%sa03',\n",
    "                     '%sa04',\n",
    "                     '%sa05',\n",
    "                     '%sa06',\n",
    "                     '%sb07',\n",
    "                     '%sb08',\n",
    "                     '%sb09',\n",
    "                     '%sb10',\n",
    "                     '%sb11',\n",
    "                     '%sb12']#,\n",
    "\n",
    "    file_names = [f % (subject_id) for f in file_exts]\n",
    "\n",
    "\n",
    "    # =============================================================================\n",
    "    # GENERAL SETTINGS\n",
    "    # =============================================================================\n",
    "\n",
    "    # Set out_path folder or create it if it doesn't exist\n",
    "    out_path = op.join(data_path, \"out_path\")\n",
    "    if not op.exists(out_path):\n",
    "        os.mkdir(out_path)\n",
    "\n",
    "    # =============================================================================\n",
    "    # MAXWELL FILTERING SETTINGS\n",
    "    # =============================================================================\n",
    "\n",
    "    # Set filtering method\n",
    "    method='sss'\n",
    "    if method == 'tsss':\n",
    "        st_duration = 10\n",
    "    else:\n",
    "        st_duration = None\n",
    "\n",
    "\n",
    "    # =============================================================================\n",
    "    # FILTERING AND DOWNSAMPLING SETTINGS\n",
    "    # =============================================================================\n",
    "\n",
    "    # Filter and resampling params\n",
    "    l_freq = 1\n",
    "    h_freq = 40\n",
    "    sfreq = 200\n",
    "\n",
    "\n",
    "    # =============================================================================\n",
    "    # ICA SETTINGS\n",
    "    # =============================================================================\n",
    "\n",
    "    ica_method = 'fastica'\n",
    "    n_components = 0.99\n",
    "    max_iter = 800\n",
    "    random_state = 1688\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load 01-maxwell_filtering.py\n",
    "\"\"\"\n",
    "===================================\n",
    "01. Maxwell filter using MNE-python\n",
    "===================================\n",
    "\n",
    "The data are Maxwell filtered using tSSS/SSS.\n",
    "\n",
    "It is critical to mark bad channels before Maxwell filtering.\n",
    "\n",
    "Open issues:\n",
    "    1. SSS or tSSS? -> Consult Alex G.?\n",
    "    \n",
    "\"\"\"  # noqa: E501\n",
    "\n",
    "\n",
    "def run_maxwell_filter(method = 'sss'):\n",
    "    # stdout_obj = sys.stdout                 # store original stdout \n",
    "    # sys.stdout = open(op.join(out_path,     # open log file\n",
    "    # os.path.basename(__file__) + \"_%s.txt\" % (site_id+subject_id)),'w')\n",
    "    \n",
    "    # Load the fine calibration file (which encodes site-specific information \n",
    "    # about sensor orientation and calibration) as well as a crosstalk \n",
    "    # compensation file (which reduces interference between Elektaâ€™s co-located\n",
    "    # magnetometer and paired gradiometer sensor units)\n",
    "    crosstalk_file = op.join(cal_path, \"ct_sparse.fif\")\n",
    "    fine_cal_file = op.join(sss_path, \"sss_cal.dat\")\n",
    "\n",
    "    # Create empty dataframe for bad channel list\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    # Prepare PDF report\n",
    "    pdf = FPDF(orientation=\"P\", unit=\"mm\", format=\"A4\")\n",
    "    \n",
    "    print(\"Processing subject: %s\" % subject_id)\n",
    "    run = 0\n",
    "    for file_name in file_names:\n",
    "        run = run + 1\n",
    "        print(\"  File: %s\" % file_name)\n",
    "        \n",
    "        # Read raw data\n",
    "        raw_fname_in = op.join(data_path, file_name + '.fif')\n",
    "        raw = mne.io.read_raw_fif(\n",
    "            raw_fname_in,\n",
    "            allow_maxshield=True,\n",
    "            preload=False,\n",
    "            verbose=True)\n",
    "        \n",
    "        # Detect bad channels\n",
    "        raw.info['bads'] = ['MEG1241','MEG2641']\n",
    "        raw_check = raw.copy()\n",
    "        auto_noisy_chs, auto_flat_chs, auto_scores = find_bad_channels_maxwell(\n",
    "            raw_check, \n",
    "            cross_talk=crosstalk_file, \n",
    "            calibration=fine_cal_file,\n",
    "            return_scores=True,\n",
    "            verbose=True)\n",
    "        raw.info['bads'].extend(auto_noisy_chs + auto_flat_chs)\n",
    "        \n",
    "        # Append bad channels to the list \n",
    "        df = df.append({'run': run,\n",
    "                        'noisy': auto_noisy_chs, \n",
    "                        'flat': auto_flat_chs},\n",
    "                        ignore_index=True)        \n",
    "        \n",
    "        # Visualize the scoring used to classify channels as noisy or flat\n",
    "        ch_type = 'grad'\n",
    "        fig = viz_badch_scores(auto_scores, ch_type)\n",
    "        fname_fig = op.join(out_path,\n",
    "                            \"01_r%s_badchannels_%sscore.png\" % (run,ch_type))\n",
    "        fig.savefig(fname_fig)\n",
    "        plt.close()\n",
    "        ch_type = 'mag'\n",
    "        fig = viz_badch_scores(auto_scores, ch_type)\n",
    "        fname_fig = op.join(out_path,\n",
    "                            \"01_r%s_badchannels_%sscore.png\" % (run,ch_type))\n",
    "        fig.savefig(fname_fig)\n",
    "        plt.close()\n",
    "        \n",
    "        # Fix Elekta magnetometer coil types\n",
    "        raw.fix_mag_coil_types()\n",
    "        # realign\n",
    "        file_name_ref=file_names[0]\n",
    "        raw_ref_fname_in = op.join(data_path, file_name_ref + '.fif')\n",
    "        raw_ref = mne.io.read_raw_fif(raw_ref_fname_in,\n",
    "            allow_maxshield=True,\n",
    "            preload=False,\n",
    "            verbose=True)\n",
    "        dev_head_t_ref = raw_ref.info['dev_head_t']\n",
    "        \n",
    "        # Perform tSSS/SSS and Maxwell filtering\n",
    "        raw_sss = mne.preprocessing.maxwell_filter(\n",
    "            raw,\n",
    "            origin='auto',\n",
    "            cross_talk=crosstalk_file,\n",
    "            calibration=fine_cal_file,\n",
    "            st_duration=st_duration,\n",
    "            coord_frame='head',\n",
    "            destination=dev_head_t_ref,\n",
    "            #coord_frame=\"meg\", #only for empy room, comment it if using HPI\n",
    "            verbose=True)\n",
    "        \n",
    "        # Show original and filtered signals\n",
    "        fig = raw.copy().pick(['meg']).plot(duration=5,\n",
    "                                            start=100,\n",
    "                                            butterfly=True)        \n",
    "        fname_fig = op.join(out_path,\n",
    "                            '01_r%s_plotraw.png' % run)\n",
    "        fig.savefig(fname_fig)\n",
    "        plt.close()\n",
    "        fig = raw_sss.copy().pick(['meg']).plot(duration=5,\n",
    "                                                start=100,\n",
    "                                                butterfly=True)\n",
    "        fname_fig = op.join(out_path,\n",
    "                            '01_r%s_plotraw%s.png' % (run,method))\n",
    "        fig.savefig(fname_fig)\n",
    "        plt.close()\n",
    "        \n",
    "        # Show original and filtered power\n",
    "        fig1 = raw.plot_psd(picks = ['meg'],fmin = 1,fmax = 100)\n",
    "        fname_fig1 = op.join(out_path,\n",
    "                            '01_r%s_plot_psd_raw100.png' % run)\n",
    "        fig1.savefig(fname_fig1)\n",
    "        plt.close()\n",
    "        fig2 = raw_sss.plot_psd(picks = ['meg'],fmin = 1,fmax = 100)\n",
    "        fname_fig2 = op.join(out_path,\n",
    "                            '01_r%s_plot_psd_raw100%s.png' % (run,method))\n",
    "        fig2.savefig(fname_fig2)\n",
    "        plt.close()\n",
    "        \n",
    "        '''\n",
    "        # Add figures to report\n",
    "        pdf.add_page()\n",
    "        pdf.set_font('helvetica', 'B', 16)\n",
    "        pdf.cell(0, 10, file_name)\n",
    "        pdf.ln(20)\n",
    "        pdf.set_font('helvetica', 'B', 12)\n",
    "        pdf.cell(0, 10, 'Power Spectrum of Raw MEG Data', 'B', ln=1)\n",
    "        pdf.image(fname_fig1, 0, 45, pdf.epw)\n",
    "        pdf.ln(120)\n",
    "        pdf.cell(0, 10, 'Power Spectrum of Filtered MEG Data', 'B', ln=1)\n",
    "        pdf.image(fname_fig2, 0, 175, pdf.epw)\n",
    "        '''\n",
    "        # Save filtered data\n",
    "        fname_out = op.join(out_path,\n",
    "                            file_name + '_' + method + '.fif')\n",
    "        raw_sss.save(fname_out, overwrite=True)\n",
    "        \n",
    "    # Save bad channel list\n",
    "    df.to_csv(op.join(out_path,\n",
    "                      '01_rAll_meg_badch_list.csv'),\n",
    "              index=False)\n",
    "    \n",
    "    # Save report\n",
    "    # pdf.output(op.join(out_path,\n",
    "    #                  'run_maxwell_filter' + '-report.pdf'))\n",
    "    \n",
    "    # sys.stdout.close()      # close log file\n",
    "    # sys.stdout = stdout_obj # restore command prompt\n",
    "\n",
    "\n",
    "def viz_badch_scores(auto_scores, ch_type):\n",
    "    fig, ax = plt.subplots(1, 4, figsize=(12, 8))\n",
    "    fig.suptitle(f'Automated noisy/flat channel detection: {ch_type}',\n",
    "                  fontsize=16, fontweight='bold')\n",
    "    \n",
    "    #### Noisy channels ####\n",
    "    ch_subset = auto_scores['ch_types'] == ch_type\n",
    "    ch_names = auto_scores['ch_names'][ch_subset]\n",
    "    scores = auto_scores['scores_noisy'][ch_subset]\n",
    "    limits = auto_scores['limits_noisy'][ch_subset]\n",
    "    bins = auto_scores['bins']  #the windows that were evaluated\n",
    "    \n",
    "    # Label each segment by its start and stop time (3 digits / 1 ms precision)\n",
    "    bin_labels = [f'{start:3.3f} â€“ {stop:3.3f}' \n",
    "                  for start, stop in bins]\n",
    "    \n",
    "    # Store  data in DataFrame\n",
    "    data_to_plot = pd.DataFrame(data=scores,\n",
    "                                columns=pd.Index(bin_labels, name='Time (s)'),\n",
    "                                index=pd.Index(ch_names, name='Channel'))\n",
    "    \n",
    "    # First, plot the raw scores\n",
    "    sns.heatmap(data=data_to_plot, \n",
    "                cmap='Reds', \n",
    "                cbar=False,\n",
    "                # cbar_kws=dict(label='Score'),\n",
    "                ax=ax[0])\n",
    "    [ax[0].axvline(x, ls='dashed', lw=0.25, dashes=(25, 15), color='gray')\n",
    "        for x in range(1, len(bins))]\n",
    "    ax[0].set_title('Noisy: All Scores', fontweight='bold')\n",
    "\n",
    "    # Second, highlight segments that exceeded the 'noisy' limit\n",
    "    sns.heatmap(data=data_to_plot,\n",
    "                vmin=np.nanmin(limits),\n",
    "                cmap='Reds', \n",
    "                cbar=True, \n",
    "                # cbar_kws=dict(label='Score'), \n",
    "                ax=ax[1])\n",
    "    [ax[1].axvline(x, ls='dashed', lw=0.25, dashes=(25, 15), color='gray')\n",
    "        for x in range(1, len(bins))]\n",
    "    ax[1].set_title('Noisy: Scores > Limit', fontweight='bold')\n",
    "    \n",
    "    #### Flat channels ####\n",
    "    ch_subset = auto_scores['ch_types'] == ch_type\n",
    "    ch_names = auto_scores['ch_names'][ch_subset]\n",
    "    scores = auto_scores['scores_flat'][ch_subset]\n",
    "    limits = auto_scores['limits_flat'][ch_subset]\n",
    "    bins = auto_scores['bins']  #the windows that were evaluated\n",
    "    \n",
    "    # Label each segment by its start and stop time (3 digits / 1 ms precision)\n",
    "    bin_labels = [f'{start:3.3f} â€“ {stop:3.3f}' \n",
    "                  for start, stop in bins]\n",
    "    \n",
    "    # Store  data in DataFrame\n",
    "    data_to_plot = pd.DataFrame(data=scores,\n",
    "                                columns=pd.Index(bin_labels, name='Time (s)'),\n",
    "                                index=pd.Index(ch_names, name='Channel'))\n",
    "    \n",
    "    # First, plot the raw scores\n",
    "    sns.heatmap(data=data_to_plot, \n",
    "                cmap='Reds', \n",
    "                cbar=False,\n",
    "                # cbar_kws=dict(label='Score'),\n",
    "                ax=ax[2])\n",
    "    [ax[2].axvline(x, ls='dashed', lw=0.25, dashes=(25, 15), color='gray')\n",
    "        for x in range(1, len(bins))]\n",
    "    ax[2].set_title('Flat: All Scores', fontweight='bold')\n",
    "\n",
    "    # Second, highlight segments that exceeded the 'noisy' limit\n",
    "    sns.heatmap(data=data_to_plot,\n",
    "                vmax=np.nanmax(limits),\n",
    "                cmap='Reds', \n",
    "                cbar=True,\n",
    "                # cbar_kws=dict(label='Score'), \n",
    "                ax=ax[3])\n",
    "    [ax[3].axvline(x, ls='dashed', lw=0.25, dashes=(25, 15), color='gray')\n",
    "        for x in range(1, len(bins))]\n",
    "    ax[3].set_title('Flat: Scores > Limit', fontweight='bold')\n",
    "    \n",
    "    # Fit figure title to not overlap with the subplots\n",
    "    fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load 03-artifact_annotation.py\n",
    "\"\"\"\n",
    "===========================\n",
    "03. Artifact annotation\n",
    "===========================\n",
    "\n",
    "Detect and note ocular and muscle artifacts\n",
    "\n",
    "Open issues:\n",
    "    1. Eye-link annot?\n",
    "    -> Ling will develop it\n",
    "\n",
    "\"\"\"  # noqa: E501\n",
    "\n",
    "\n",
    "def artifact_annotation():  \n",
    "    # stdout_obj = sys.stdout                 # store original stdout \n",
    "    # sys.stdout = open(op.join(out_path,     # open log file\n",
    "                              # os.path.basename(__file__) + \"_%s.txt\" % (site_id+subject_id)),'w')\n",
    "    \n",
    "    # Prepare PDF report\n",
    "    pdf = FPDF(orientation=\"P\", unit=\"mm\", format=\"A4\")    \n",
    "    print(\"Processing subject: %s\" % subject_id)\n",
    "    run = 0\n",
    "    for file_name in file_names:\n",
    "        run = run + 1\n",
    "        print(\"  File: %s\" % file_name)\n",
    "        \n",
    "        # Read raw data\n",
    "        raw_fname_in = op.join(out_path,\n",
    "                               file_name + '_sss.fif')\n",
    "        raw = mne.io.read_raw_fif(\n",
    "            raw_fname_in, \n",
    "            preload=True, \n",
    "            verbose='error')\n",
    "        \n",
    "        # Create empty annotations list\n",
    "        annot_artifact = mne.Annotations(onset=[], \n",
    "                                         duration=[],\n",
    "                                         description=[])\n",
    "        \n",
    "        ###########################\n",
    "        # Detect ocular artifacts #\n",
    "        ###########################\n",
    "        \n",
    "        # Resetting the EOG channel\n",
    "        \"\"\"\n",
    "        eog_ch = raw.copy().pick_types(meg=False, eeg=False, eog=True)\n",
    "        if len(eog_ch.ch_names) < 2:\n",
    "            raw.set_channel_types({'BIO002':'eog'})\n",
    "            raw.rename_channels({'BIO002': 'EOG002'})\n",
    "            \n",
    "            # Find EOG events\n",
    "            eog_events = mne.preprocessing.find_eog_events(raw)\n",
    "            onsets = (eog_events[:, 0] - raw.first_samp) / raw.info['sfreq'] - 0.25\n",
    "            durations = [0.5] * len(eog_events)\n",
    "            descriptions = ['Blink'] * len(eog_events)\n",
    "            \n",
    "            # Annotate events\n",
    "            annot_blink = mne.Annotations(\n",
    "                onsets, \n",
    "                durations,\n",
    "                descriptions)\n",
    "                # orig_time=raw.info['meas_date'])\n",
    "            \n",
    "            # Add blinks to annotations list\n",
    "            annot_artifact = annot_artifact + annot_blink\n",
    "            \n",
    "            # Plot blink with EEG data\n",
    "            eeg_picks = mne.pick_types(raw.info, \n",
    "                                      meg=False,\n",
    "                                      eeg=True,\n",
    "                                      eog=True)\n",
    "#             print(eog_events)\n",
    "            fig = raw.plot(events=eog_events,\n",
    "                          start=400,  ### correction: 800 -> 400 no element if too high\n",
    "                          order=eeg_picks)\n",
    "            fname_fig = op.join(out_path,\n",
    "                               \"03_r%s_artifact_blink.png\" % run)\n",
    "            fig.savefig(fname_fig)\n",
    "            plt.close()\n",
    "        \"\"\"\n",
    "        ###########################\n",
    "        # Detect muscle artifacts #\n",
    "        ###########################\n",
    "        \n",
    "        # Notch filter\n",
    "        raw_muscle = raw.copy().notch_filter([50, 100])\n",
    "        \n",
    "        # The threshold is data dependent, check the optimal threshold by plotting\n",
    "        # ``scores_muscle``.\n",
    "        threshold_muscle = 5  # z-score\n",
    "        \n",
    "        # Choose one channel type, if there are axial gradiometers and magnetometers,\n",
    "        # select magnetometers as they are more sensitive to muscle activity.\n",
    "        annot_muscle, scores_muscle = annotate_muscle_zscore(\n",
    "            raw_muscle, \n",
    "            ch_type=\"mag\", \n",
    "            threshold=threshold_muscle, \n",
    "            min_length_good=0.2,\n",
    "            filter_freq=[110, 140])\n",
    "        \n",
    "        # Add muscle artifacts to annotations list\n",
    "        annot_artifact = annot_artifact + annot_muscle\n",
    "        \n",
    "        # Plot muscle z-scores across recording\n",
    "        fig1, ax = plt.subplots()\n",
    "        ax.plot(raw.times, scores_muscle)\n",
    "        ax.axhline(y=threshold_muscle, color='r')\n",
    "        ax.set(xlabel='time, (s)', ylabel='zscore', title='Muscle activity')\n",
    "        fname_fig1 = op.join(out_path,\n",
    "                            \"03_r%s_artifact_muscle.png\" % run)\n",
    "        fig1.savefig(fname_fig1)\n",
    "        plt.close()\n",
    "        \n",
    "        '''\n",
    "        # Add figure to report\n",
    "        pdf.add_page()\n",
    "        pdf.set_font('helvetica', 'B', 16)\n",
    "        pdf.cell(0, 10, file_name)\n",
    "        pdf.ln(20)\n",
    "        pdf.set_font('helvetica', 'B', 12)\n",
    "        pdf.cell(0, 10, 'Muscle artifact power', 'B', ln=1)\n",
    "        pdf.image(fname_fig1, 0, 45, pdf.epw)\n",
    "        '''\n",
    "        ###########################\n",
    "        \n",
    "        # Set annotations\n",
    "        raw.set_annotations(annot_artifact)\n",
    "        \n",
    "        # View raw with annotations\n",
    "        channel_picks = mne.pick_types(raw.info, \n",
    "                                       meg='mag', eog=True)\n",
    "        fig2 = raw.plot(duration=50,\n",
    "                       start=100,\n",
    "                       order=channel_picks)\n",
    "        fname_fig2 = op.join(out_path,\n",
    "                            \"03_r%s_artifact_annot.png\" % run)\n",
    "        fig2.savefig(fname_fig2)\n",
    "        plt.close()\n",
    "        \n",
    "        '''\n",
    "        # Add figures to report\n",
    "        pdf.ln(120)\n",
    "        pdf.cell(0, 10, 'Data and annotations', 'B', ln=1)\n",
    "        pdf.image(fname_fig2, 0, 175, pdf.epw)\n",
    "        '''\n",
    "        \n",
    "        # Save data with annotated artifacts\n",
    "        fname_out = op.join(out_path,\n",
    "                            file_name + '_artif.fif')                            \n",
    "        raw.save(fname_out, overwrite=True)\n",
    "    \n",
    "    # Save report\n",
    "    pdf.output(op.join(out_path,\n",
    "                       'artifact_annotation' + '-report.pdf'))\n",
    "    \n",
    "    # sys.stdout.close()      # close log file\n",
    "    # sys.stdout = stdout_obj # restore command prompt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load 04-extract_events.py\n",
    "\"\"\"\n",
    "===================\n",
    "04. Extract events\n",
    "===================\n",
    "\n",
    "Extract events from the stimulus channel\n",
    "\n",
    "Open issues:\n",
    "    - metadata for exp 2 needs to be created\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def run_events():\n",
    "    \n",
    "    # stdout_obj = sys.stdout                 # store original stdout \n",
    "    # sys.stdout = open(op.join(out_path,     # open log file\n",
    "                              # os.path.basename(__file__) + \"_%s.txt\" % (site_id+subject_id)),'w')\n",
    "    \n",
    "    # Prepare PDF report\n",
    "    pdf = FPDF(orientation=\"P\", unit=\"mm\", format=\"A4\")\n",
    "\n",
    "    print(\"Processing subject: %s\" % subject_id)\n",
    "    run = 0\n",
    "    for file_name in file_names:\n",
    "        run = run + 1\n",
    "        print(\"  File: %s\" % file_name)\n",
    "        \n",
    "        # Read raw data\n",
    "        run_fname = op.join(data_path,\n",
    "                            file_name + '.fif')\n",
    "        raw = mne.io.read_raw_fif(\n",
    "            run_fname,\n",
    "            allow_maxshield=True,\n",
    "            verbose=True)\n",
    "        \n",
    "        ###############\n",
    "        # Read events #\n",
    "        ###############\n",
    "    \n",
    "        \n",
    "        # Find all events\n",
    "        events = mne.find_events(raw,\n",
    "                                 stim_channel='STI101',\n",
    "                                 consecutive = True,\n",
    "                                 min_duration=0.001001,\n",
    "                                 mask = 65280,\n",
    "                                 mask_type = 'not_and'\n",
    "                                )\n",
    "        events = events[events[:,2] != 255]\n",
    "        \n",
    "        # Concatenate all events\n",
    "        events = np.concatenate([events],axis = 0)\n",
    "        events = events[events[:,0].argsort(),:]\n",
    "        \n",
    "        # Show events\n",
    "        fig = mne.viz.plot_events(events)\n",
    "        fname_fig = op.join(out_path,\n",
    "                            \"04_r%s_events.png\" % run)\n",
    "        fig.savefig(fname_fig)\n",
    "        plt.close(fig)\n",
    "        \n",
    "        '''\n",
    "        # Add figure to report\n",
    "        pdf.add_page()\n",
    "        pdf.set_font('helvetica', 'B', 16)\n",
    "        pdf.cell(0, 10, file_name)\n",
    "        pdf.ln(20)\n",
    "        pdf.set_font('helvetica', 'B', 12)\n",
    "        pdf.cell(0, 10, 'Events', 'B', ln=1)\n",
    "        pdf.image(fname_fig, 0, 45, pdf.epw)\n",
    "        '''\n",
    "        # Save event array\n",
    "        fname_events = op.join(out_path,\n",
    "                               file_name + '-eve.fif')                            \n",
    "        mne.write_events(fname_events, events)\n",
    "        \n",
    "    # Save report\n",
    "    # pdf.output(op.join(out_path,\n",
    "    #                   'run_events' + '-report.pdf'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load 05-run_ica.py\n",
    "\"\"\"\n",
    "===========\n",
    "05. Run ICA\n",
    "===========\n",
    "\n",
    "Open issues:\n",
    "    1. why the EEG-specific ICA gives only a few components?\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def run_ica(max_iter = 100, n_components = 0.99, random_state = 1):\n",
    "    \n",
    "    # stdout_obj = sys.stdout                 # store original stdout \n",
    "    # sys.stdout = open(op.join(out_path,     # open log file\n",
    "    #                           os.path.basename(__file__) + \"_%s.txt\" % (site_id+subject_id)),'w')\n",
    "    print('\\n\\n\\n\\n\\n#######################################################################################')\n",
    "    print(\"Processing subject: %s\" % subject_id)\n",
    "    run = 0\n",
    "    for file_name in file_names:\n",
    "        run = run + 1\n",
    "        print(\"  File: %s\" % file_name)\n",
    "        \n",
    "        # Read raw data\n",
    "        raw_fname_in = op.join(out_path,\n",
    "                               file_name + '_artif.fif')\n",
    "        raw = mne.io.read_raw_fif(\n",
    "            raw_fname_in, \n",
    "            preload=True, \n",
    "            verbose='error')\n",
    "        \n",
    "        # Downsample copy of raw\n",
    "        raw_resmpl = raw.copy().resample(sfreq)\n",
    "            \n",
    "        # Band-pass filter raw copy\n",
    "        raw_resmpl.filter(l_freq, h_freq)\n",
    "            \n",
    "        # Concatenate raw copies\n",
    "        if run == 1:\n",
    "            raw_resmpl_all = mne.io.concatenate_raws([raw_resmpl])\n",
    "        else:\n",
    "            raw_resmpl_all = mne.io.concatenate_raws([raw_resmpl_all, raw_resmpl])\n",
    "        \n",
    "        del raw, raw_resmpl\n",
    "    \n",
    "    ###################\n",
    "    # ICA on MEG data #\n",
    "    ###################\n",
    "    \n",
    "    # Prepare PDF report\n",
    "    pdf = FPDF(orientation=\"P\", unit=\"mm\", format=\"A4\")\n",
    "    \n",
    "    # Define ICA settings\n",
    "    ica = ICA(method=ica_method,\n",
    "              random_state=random_state,\n",
    "              n_components=n_components,\n",
    "              verbose=True)\n",
    "    \n",
    "    # Run ICA on filtered raw data\n",
    "    ica.fit(raw_resmpl_all,\n",
    "            picks='meg',\n",
    "            verbose=True)\n",
    "    \n",
    "    # Plot timecourse of estimated sources\n",
    "    fig = ica.plot_sources(raw_resmpl_all,\n",
    "                           start=100,\n",
    "                           show_scrollbars=False,\n",
    "                           title='ICA_MEG')\n",
    "    \n",
    "    # for i in range(len(fig)):\n",
    "    #     fname_fig = op.join(out_path, \n",
    "    #                         '05_rAll_ica_meg_src%d' % i)\n",
    "    #     fig[i].savefig(fname_fig)\n",
    "    #     plt.close(fig[i])\n",
    "\n",
    "    fname_fig = op.join(out_path, \n",
    "                      \"05_rAll_ica_meg_src.png\")\n",
    "    fig.savefig(fname_fig)\n",
    "    plt.close(fig)\n",
    "    \n",
    "    '''\n",
    "    # Add figure to report\n",
    "    pdf.add_page()\n",
    "    pdf.set_font('helvetica', 'B', 16)\n",
    "    pdf.cell(0, 10, file_names[0][0:13] + ' - MEG')\n",
    "    pdf.ln(20)\n",
    "    pdf.set_font('helvetica', 'B', 12)\n",
    "    pdf.cell(0, 10, 'Timecourse of MEG ICs', 'B', ln=1)\n",
    "    pdf.image(fname_fig, 0, 45, pdf.epw)\n",
    "    '''\n",
    "    # Project mixing matrix on interpolated sensor topography\n",
    "    fig = ica.plot_components(title='ICA_MEG')\n",
    "    for i in range(len(fig)):\n",
    "        fname_fig = op.join(out_path, \n",
    "                            '05_rAll_ica_meg_cmp%d.png' % i)\n",
    "        fig[i].savefig(fname_fig)\n",
    "        plt.close(fig[i])\n",
    "        \n",
    "        '''\n",
    "        # Add figure to report\n",
    "        pdf.add_page()\n",
    "        pdf.set_font('helvetica', 'B', 16)\n",
    "        pdf.cell(0, 10, file_names[0][0:13] + ' - MEG')\n",
    "        pdf.ln(20)\n",
    "        pdf.set_font('helvetica', 'B', 12)\n",
    "        pdf.cell(0, 10, 'Topography of MEG ICs', 'B', ln=1)\n",
    "        pdf.image(fname_fig, 0, 45, pdf.epw)\n",
    "        \n",
    "        '''\n",
    "    # Save files\n",
    "    ica_fname = op.join(out_path,\n",
    "                        subject_id + 'ALL-ica_meg.fif')\n",
    "    ica.save(ica_fname)\n",
    "    \n",
    "    # Save report\n",
    "    pdf.output(op.join(out_path,\n",
    "                       'run_ica' + '-reportMEG.pdf'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %load config.py\n",
    "\"\"\"\n",
    "===========\n",
    "Config file\n",
    "===========\n",
    "\n",
    "Configurate the parameters of the study.\n",
    "\"\"\"\n",
    "for subject_id in subject_list[:1]:\n",
    "\n",
    "    # =============================================================================\n",
    "    # SESSION-SPECIFIC SETTINGS\n",
    "    # =============================================================================\n",
    "\n",
    "    # Set filename based on experiment number\n",
    "    file_exts = ['%sa01',\n",
    "                     '%sa02',\n",
    "                     '%sa03',\n",
    "                     '%sa04',\n",
    "                     '%sa05',\n",
    "                     '%sa06',\n",
    "                     '%sb07',\n",
    "                     '%sb08',\n",
    "                     '%sb09',\n",
    "                     '%sb10',\n",
    "                     '%sb11',\n",
    "                     '%sb12']\n",
    "\n",
    "    file_names = [f % (subject_id) for f in file_exts]\n",
    "\n",
    "\n",
    "    # =============================================================================\n",
    "    # GENERAL SETTINGS\n",
    "    # =============================================================================\n",
    "\n",
    "    # Set out_path folder or create it if it doesn't exist\n",
    "    out_path = op.join(data_path, \"out_path\")\n",
    "    if not op.exists(out_path):\n",
    "        os.mkdir(out_path)\n",
    "\n",
    "\n",
    "    # =============================================================================\n",
    "    # MAXWELL FILTERING SETTINGS\n",
    "    # =============================================================================\n",
    "\n",
    "    # Set filtering method\n",
    "    method='sss'\n",
    "    if method == 'tsss':\n",
    "        st_duration = 10\n",
    "    else:\n",
    "        st_duration = None\n",
    "\n",
    "\n",
    "    # =============================================================================\n",
    "    # FILTERING AND DOWNSAMPLING SETTINGS\n",
    "    # =============================================================================\n",
    "\n",
    "    # Filter and resampling params\n",
    "    l_freq = 1\n",
    "    h_freq = 40\n",
    "    sfreq = 200\n",
    "\n",
    "\n",
    "    # =============================================================================\n",
    "    # ICA SETTINGS\n",
    "    # =============================================================================\n",
    "\n",
    "    ica_method = 'fastica'\n",
    "    n_components = 0.99\n",
    "    max_iter = 800\n",
    "    random_state = 1688\n",
    "\n",
    "\n",
    "    # =============================================================================\n",
    "    # RUN\n",
    "    # =============================================================================\n",
    "\n",
    "    # run_maxwell_filter(method=method)\n",
    "\n",
    "\n",
    "    # artifact_annotation()\n",
    "\n",
    "    # run_events()\n",
    "    \n",
    "    run_ica(max_iter = max_iter, \n",
    "            n_components = n_components, \n",
    "            random_state = random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load 06-apply_ica.py\n",
    "\"\"\"\n",
    "===============\n",
    "06. Apply ICA\n",
    "===============\n",
    "\n",
    "This relies on the ICAs computed in 05-run_ica.py\n",
    "\n",
    "Open issues:\n",
    "    1. Should we automitaze EOG- and ECG-related ICs detection?\n",
    "    -> up to Ling and Oscar. Do auto and cross-check afterwards\n",
    "    2. Add plots?\n",
    "    -> no\n",
    "    3. How many comps per type should we remove?\n",
    "    -> 1-2 each (if any). 2-5 in total\n",
    "    4. Apply on concatenated data? -> Yes\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "def apply_ica(meg_ica_eog = [], meg_ica_ecg = []):\n",
    "\n",
    "    # Prepare PDF report\n",
    "    pdf = FPDF(orientation=\"P\", unit=\"mm\", format=\"A4\")\n",
    "    \n",
    "    print(\"Processing subject: %s\" % subject_id)\n",
    "    run = 0\n",
    "    for file_name in file_names:\n",
    "        run = run + 1\n",
    "        print(\"  File: %s\" % file_name)\n",
    "        \n",
    "        # Read raw data\n",
    "        raw_fname_in = op.join(out_path,\n",
    "                               file_name + '_artif.fif')\n",
    "        raw = mne.io.read_raw_fif(\n",
    "            raw_fname_in, \n",
    "            preload=True, \n",
    "            verbose='error')\n",
    "        \n",
    "        # Show original signal\n",
    "\n",
    "        chs = ['MEG0311', 'MEG0121', 'MEG1211', 'MEG1411']\n",
    "        chan_idxs = [raw.ch_names.index(ch) for ch in chs]\n",
    "        fig1 = raw.plot(order=chan_idxs,\n",
    "                       duration=50,\n",
    "                       start=100)        \n",
    "        fname_fig1 = op.join(out_path,\n",
    "                            '06_r%s_ica_raw0.png' % run)\n",
    "        fig1.savefig(fname_fig1)\n",
    "        plt.close()\n",
    "        \n",
    "        '''\n",
    "        # Add figure to report\n",
    "        pdf.add_page()\n",
    "        pdf.set_font('helvetica', 'B', 16)\n",
    "        pdf.cell(0, 10, file_name)\n",
    "        pdf.ln(20)\n",
    "        pdf.set_font('helvetica', 'B', 12)\n",
    "        pdf.cell(0, 10, 'Timecourse of input data', 'B', ln=1)\n",
    "        pdf.image(fname_fig1, 0, 45, pdf.epw)\n",
    "        '''\n",
    "        ###################\n",
    "        # ICA on MEG data #\n",
    "        ###################\n",
    "        \n",
    "        if [meg_ica_eog + meg_ica_ecg] != []:\n",
    "            \n",
    "            # Restore ICA solution from fif file\n",
    "            ica_meg_fname = op.join(out_path,\n",
    "                               subject_id + 'ALL-ica_meg.fif')\n",
    "            ica_meg = read_ica(ica_meg_fname)\n",
    "            \n",
    "            # Select EOG- and ECG-related components for exclusion\n",
    "            ica_meg.exclude.extend(meg_ica_eog + meg_ica_ecg)\n",
    "            \n",
    "            # # Plot excluded ICs\n",
    "            # if meg_ica_eog != []:\n",
    "            #     # Display component properties\n",
    "            #     fig = ica.plot_properties(raw, \n",
    "            #                               picks=meg_ica_eog)\n",
    "            #     for i in range(len(fig)):\n",
    "            #         fname_fig = op.join(out_path, \n",
    "            #                             \"04_r%s_ica_meg_eog%d.png\" % (run,i))\n",
    "            #         fig[i].savefig(fname_fig)\n",
    "            #         plt.close(fig[i])\n",
    "            # if meg_ica_ecg != []:\n",
    "            #     # Display component properties\n",
    "            #     fig = ica.plot_properties(raw, \n",
    "            #                               picks=meg_ica_ecg)\n",
    "            #     for i in range(len(fig)):\n",
    "            #         fname_fig = op.join(out_path, \n",
    "            #                             \"04_r%s_ica_meg_ecg%d.png\" % (run,i))\n",
    "            #         fig[i].savefig(fname_fig)\n",
    "            #         plt.close(fig[i])\n",
    "            \n",
    "        \n",
    "        ###################\n",
    "        \n",
    "        # Remove selected components from the signal  #TODO: @Ling why \"apply\" is done in two different steps?\n",
    "        raw_ica = raw.copy()\n",
    "        ica_meg.apply(raw_ica)\n",
    "        \n",
    "        # Show cleaned signal\n",
    "        fig_ica = raw_ica.plot(order=chan_idxs,\n",
    "                               duration=50,\n",
    "                               start=100)        \n",
    "        fname_fig_ica = op.join(out_path,\n",
    "                                '06_r%s_ica_rawICA.png' % run)\n",
    "        fig_ica.savefig(fname_fig_ica)\n",
    "        plt.close()\n",
    "        \n",
    "        '''\n",
    "        # Add figures to report\n",
    "        pdf.ln(120)\n",
    "        pdf.cell(0, 10, 'Timecourse of output data', 'B', ln=1)\n",
    "        pdf.image(fname_fig_ica, 0, 175, pdf.epw)\n",
    "        '''\n",
    "        # Save cleaned raw data\n",
    "        fname_out = op.join(out_path,\n",
    "                            file_name + '_ica.fif')\n",
    "        raw_ica.save(fname_out,overwrite=True)\n",
    "    \n",
    "    # Save report  #TODO: add note about removed ICs\n",
    "    pdf.output(op.join(out_path,\n",
    "                       'apply_ica' + '-report.pdf'))\n",
    "    \n",
    "    # sys.stdout.close()      # close log file\n",
    "    # sys.stdout = stdout_obj # restore command prompt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load 07-make_epochs.py\n",
    "\"\"\"\n",
    "====================\n",
    "07. Make epochs\n",
    "====================\n",
    "\n",
    "Open issues:\n",
    "    - baseline correction -> removed\n",
    "    - apply (SSP) projections?\n",
    "    - separate MEG and EEG in two different FIF files?\n",
    "    - Exp.2: separate VG and replay in two different files?\n",
    "    - detrand required for EEG data: when do we apply it? to epochs or to events?\n",
    "    - remove peak-to-peak rejection?\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def run_epochs():\n",
    "\n",
    "    # stdout_obj = sys.stdout                 # store original stdout \n",
    "    # sys.stdout = open(op.join(out_path,     # open log file\n",
    "    #                            os.path.basename(__file__) + \"_%s.txt\" % (site_id+subject_id)),'w')\n",
    "    \n",
    "    # Prepare PDF report\n",
    "    pdf = FPDF(orientation=\"P\", unit=\"mm\", format=\"A4\")\n",
    "    \n",
    "    print(\"Processing subject: %s\" % subject_id)\n",
    "    \n",
    "    # Create empty lists\n",
    "    raw_list = list()\n",
    "    events_list = list()\n",
    "    # metadata_list = list()\n",
    "    \n",
    "    print(\"Processing subject: %s\" % subject_id)\n",
    "    run = 0\n",
    "    for file_name in file_names:\n",
    "        run = run + 1\n",
    "        print(\"  File: %s\" % file_name)\n",
    "        \n",
    "        # Read raw data\n",
    "        raw_fname_in = op.join(out_path,\n",
    "                               file_name + '_ica.fif')\n",
    "        raw_tmp = mne.io.read_raw_fif(\n",
    "            raw_fname_in, \n",
    "            preload=True, \n",
    "            verbose='error')\n",
    "        raw_tmp.filter(1,100)\n",
    "        \n",
    "        # Read events\n",
    "        events_tmp = mne.read_events(op.join(out_path,\n",
    "                                             file_name + '-eve.fif'))                           \n",
    "        # Read metadata\n",
    "        # metadata_tmp = pd.read_csv(op.join(out_path,\n",
    "        #                                   file_name + '-meta.csv'))\n",
    "        \n",
    "        # Append read data to list\n",
    "        raw_list.append(raw_tmp)\n",
    "        events_list.append(events_tmp)\n",
    "        # metadata_list.append(metadata_tmp)\n",
    "\n",
    "    # Concatenate raw instances as if they were continuous\n",
    "    raw, events = mne.concatenate_raws(raw_list,\n",
    "                                       events_list=events_list)\n",
    "    del raw_list\n",
    "    \n",
    "    # Concatenate metadata tables\n",
    "    # metadata = pd.concat(metadata_list)\n",
    "    # metadata.to_csv(op.join(out_path,\n",
    "    #                    file_name[0:14] + 'ALL-meta.csv'),\n",
    "    #                index=False)\n",
    "    \n",
    "    # Set reject criteria\n",
    "    \n",
    "    reject = reject_meg\n",
    "    \n",
    "    # Select sensor types\n",
    "    #picks = mne.pick_types(raw.info,\n",
    "    #                       meg = True,\n",
    "    #                       stim = True)\n",
    "    \n",
    "    # Epoch raw data\n",
    "    epochs = mne.Epochs(raw,\n",
    "                        events, \n",
    "                        events_id,\n",
    "                        tmin, tmax,\n",
    "                        baseline=None,\n",
    "                        proj=True,\n",
    "                        picks='all',\n",
    "                        detrend=1,\n",
    "                        reject=reject,\n",
    "                        reject_by_annotation=True,\n",
    "                        verbose=True)\n",
    "    \n",
    "    # epochs.metadata = metadata\n",
    "    \n",
    "    del raw\n",
    "    \n",
    "    # Add metadata\n",
    "    # epochs.metadata = metadata\n",
    "    \n",
    "    # Drop bad epochs based on peak-to-peak magnitude\n",
    "    epochs.drop_bad()\n",
    "    \n",
    "    # Plot percentage of rejected epochs per channel\n",
    "    fig1 = epochs.plot_drop_log()\n",
    "    fname_fig1 = op.join(out_path,\n",
    "                        '07_rAll_epoch_drop.png')\n",
    "    fig1.savefig(fname_fig1)\n",
    "    plt.close()\n",
    "    \n",
    "    '''\n",
    "    # Add figure to report\n",
    "    pdf.add_page()\n",
    "    pdf.set_font('helvetica', 'B', 16)\n",
    "    pdf.cell(0, 10, file_name)\n",
    "    pdf.ln(20)\n",
    "    pdf.set_font('helvetica', 'B', 12)\n",
    "    pdf.cell(0, 10, 'Percentage of rejected epochs', 'B', ln=1)\n",
    "    pdf.image(fname_fig1, 0, 45, pdf.epw)\n",
    "    '''\n",
    "    # Plot evoked by epoch\n",
    "    fig2 = epochs.plot(picks='meg',\n",
    "                      title='meg',\n",
    "                      n_epochs=10)\n",
    "    fname_fig2 = op.join(out_path,\n",
    "                        '07_rAll_epoch_evk.png')\n",
    "    fig2.savefig(fname_fig2)\n",
    "    plt.close(fig2)\n",
    "    \n",
    "    '''\n",
    "    # Add figures to report\n",
    "    pdf.ln(120)\n",
    "    pdf.cell(0, 10, 'Epoched data', 'B', ln=1)\n",
    "    pdf.image(fname_fig2, 0, 175, pdf.epw)\n",
    "    '''\n",
    "    # Count the number of epochs defined by different events\n",
    "    # Save epoched data\n",
    "    epochs.save(op.join(out_path,\n",
    "                        file_names[0][0:13] + 'ALL_epo.fif'),                           \n",
    "                    overwrite=True)\n",
    "    \n",
    "    # Save report  #TODO: add note about removed ICs\n",
    "    pdf.output(op.join(out_path,\n",
    "                       'run_epochs' + '-report.pdf'))\n",
    "    \n",
    "    # sys.stdout.close()      # close log file\n",
    "    # sys.stdout = stdout_obj # restore command prompt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica_choice=[[6],[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load config.py\n",
    "\"\"\"\n",
    "===========\n",
    "Config file\n",
    "===========\n",
    "\n",
    "Configurate the parameters of the study.\n",
    "\"\"\"\n",
    "\n",
    "for subject_id in subject_list[1:]:\n",
    "\n",
    "    # =============================================================================\n",
    "    # SESSION-SPECIFIC SETTINGS\n",
    "    # =============================================================================\n",
    "\n",
    "    # Set filename based on experiment number\n",
    "    file_exts = ['%sa01',\n",
    "                     '%sa02',\n",
    "                     '%sa03',\n",
    "                     '%sa04',\n",
    "                     '%sa05',\n",
    "                     '%sa06',\n",
    "                     '%sb07',\n",
    "                     '%sb08',\n",
    "                     '%sb09',\n",
    "                     '%sb10',\n",
    "                     '%sb11',\n",
    "                     '%sb12']#,\n",
    "\n",
    "    file_names = [f % (subject_id) for f in file_exts]\n",
    "\n",
    "\n",
    "    # =============================================================================\n",
    "    # GENERAL SETTINGS\n",
    "    # =============================================================================\n",
    "\n",
    "    # Set out_path folder or create it if it doesn't exist\n",
    "    out_path = op.join(data_path, \"out_path\")\n",
    "    if not op.exists(out_path):\n",
    "        os.mkdir(out_path)\n",
    "\n",
    "\n",
    "    # =============================================================================\n",
    "    # MAXWELL FILTERING SETTINGS\n",
    "    # =============================================================================\n",
    "\n",
    "    # Set filtering method\n",
    "    method='sss'\n",
    "    if method == 'tsss':\n",
    "        st_duration = 10\n",
    "    else:\n",
    "        st_duration = None\n",
    "\n",
    "\n",
    "    # =============================================================================\n",
    "    # FILTERING AND DOWNSAMPLING SETTINGS\n",
    "    # =============================================================================\n",
    "\n",
    "    # Filter and resampling params\n",
    "    l_freq = 1\n",
    "    h_freq = 40\n",
    "    sfreq = 200\n",
    "\n",
    "\n",
    "    # =============================================================================\n",
    "    # EPOCHING SETTINGS\n",
    "    # =============================================================================\n",
    "\n",
    "    # Set timewindow\n",
    "    tmin = -0.5\n",
    "    tmax = 8.1\n",
    "\n",
    "    # Epoch rejection criteria\n",
    "    reject_meg = dict(grad=4000e-13,    # T / m (gradiometers)\n",
    "                      mag=4e-12         # T (magnetometers)\n",
    "                      )\n",
    "\n",
    "    # Set epoching event ids\n",
    "\n",
    "    events_id = 101\n",
    "\n",
    "\n",
    "\n",
    "    # =============================================================================\n",
    "    # ICA SETTINGS\n",
    "    # =============================================================================\n",
    "\n",
    "    ica_method = 'fastica'\n",
    "    n_components = 0.99\n",
    "    max_iter = 800\n",
    "    random_state = 1688\n",
    "\n",
    "\n",
    "    # =============================================================================\n",
    "    #  FACTOR AND CONDITIONS OF INTEREST\n",
    "    # =============================================================================\n",
    "\n",
    "    \n",
    "    # factor = 'Category'\n",
    "    # conditions = ['face', 'object', 'letter', 'false']\n",
    "\n",
    "        # factor = 'Relevance'\n",
    "        # conditions = ['Relevant target','Relevant non-target','Irrelevant']\n",
    "\n",
    "\n",
    "    # =============================================================================\n",
    "    # TIME-FREQUENCY REPRESENTATION SETTINGS\n",
    "    # =============================================================================\n",
    "\n",
    "    baseline_w = [-0.5, -0.25]     #only for plotting\n",
    "    freq_band = 'both' #can be 'low', 'high' or 'both'\n",
    "\n",
    "    # =============================================================================\n",
    "    # RUN\n",
    "    # =============================================================================\n",
    "\n",
    "    # meg_ica_eog,meg_ica_ecg = ica_choice[0],ica_choice[1]\n",
    "    \n",
    "    #apply_ica(meg_ica_eog = meg_ica_eog,\n",
    "    #          meg_ica_ecg = meg_ica_ecg)\n",
    "\n",
    "    run_epochs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject: mg99\n",
      "Processing subject: mg99\n",
      "  File: mg99a01\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 1e+02 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 100.00 Hz\n",
      "- Upper transition bandwidth: 25.00 Hz (-6 dB cutoff frequency: 112.50 Hz)\n",
      "- Filter length: 3301 samples (3.301 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 306 out of 306 | elapsed:    4.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  File: mg99a02\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 1e+02 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 100.00 Hz\n",
      "- Upper transition bandwidth: 25.00 Hz (-6 dB cutoff frequency: 112.50 Hz)\n",
      "- Filter length: 3301 samples (3.301 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 306 out of 306 | elapsed:    4.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  File: mg99a03\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 1e+02 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 100.00 Hz\n",
      "- Upper transition bandwidth: 25.00 Hz (-6 dB cutoff frequency: 112.50 Hz)\n",
      "- Filter length: 3301 samples (3.301 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 306 out of 306 | elapsed:    4.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  File: mg99a04\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 1e+02 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 100.00 Hz\n",
      "- Upper transition bandwidth: 25.00 Hz (-6 dB cutoff frequency: 112.50 Hz)\n",
      "- Filter length: 3301 samples (3.301 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 306 out of 306 | elapsed:    4.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  File: mg99a05\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 1e+02 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 100.00 Hz\n",
      "- Upper transition bandwidth: 25.00 Hz (-6 dB cutoff frequency: 112.50 Hz)\n",
      "- Filter length: 3301 samples (3.301 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 306 out of 306 | elapsed:    4.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  File: mg99a06\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 1e+02 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 100.00 Hz\n",
      "- Upper transition bandwidth: 25.00 Hz (-6 dB cutoff frequency: 112.50 Hz)\n",
      "- Filter length: 3301 samples (3.301 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 306 out of 306 | elapsed:    4.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  File: mg99b07\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 1e+02 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 100.00 Hz\n",
      "- Upper transition bandwidth: 25.00 Hz (-6 dB cutoff frequency: 112.50 Hz)\n",
      "- Filter length: 3301 samples (3.301 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 306 out of 306 | elapsed:    5.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  File: mg99b08\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 1e+02 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 100.00 Hz\n",
      "- Upper transition bandwidth: 25.00 Hz (-6 dB cutoff frequency: 112.50 Hz)\n",
      "- Filter length: 3301 samples (3.301 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 306 out of 306 | elapsed:    4.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  File: mg99b09\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 1e+02 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 100.00 Hz\n",
      "- Upper transition bandwidth: 25.00 Hz (-6 dB cutoff frequency: 112.50 Hz)\n",
      "- Filter length: 3301 samples (3.301 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 306 out of 306 | elapsed:    4.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  File: mg99b10\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 1e+02 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 100.00 Hz\n",
      "- Upper transition bandwidth: 25.00 Hz (-6 dB cutoff frequency: 112.50 Hz)\n",
      "- Filter length: 3301 samples (3.301 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 306 out of 306 | elapsed:    4.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  File: mg99b11\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 1e+02 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 100.00 Hz\n",
      "- Upper transition bandwidth: 25.00 Hz (-6 dB cutoff frequency: 112.50 Hz)\n",
      "- Filter length: 3301 samples (3.301 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 306 out of 306 | elapsed:    3.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  File: mg99b12\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 1e+02 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 100.00 Hz\n",
      "- Upper transition bandwidth: 25.00 Hz (-6 dB cutoff frequency: 112.50 Hz)\n",
      "- Filter length: 3301 samples (3.301 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 306 out of 306 | elapsed:    3.8s finished\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 22.4 GiB for an array with shape (310, 9688000) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 106\u001b[0m\n\u001b[0;32m     96\u001b[0m freq_band \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mboth\u001b[39m\u001b[39m'\u001b[39m \u001b[39m#can be 'low', 'high' or 'both'\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[39m# =============================================================================\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[39m# RUN\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[39m# =============================================================================\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[39m#apply_ica(meg_ica_eog = meg_ica_eog,\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[39m#          meg_ica_ecg = meg_ica_ecg)\u001b[39;00m\n\u001b[1;32m--> 106\u001b[0m run_epochs()\n",
      "Cell \u001b[1;32mIn[6], line 62\u001b[0m, in \u001b[0;36mrun_epochs\u001b[1;34m()\u001b[0m\n\u001b[0;32m     58\u001b[0m     events_list\u001b[39m.\u001b[39mappend(events_tmp)\n\u001b[0;32m     59\u001b[0m     \u001b[39m# metadata_list.append(metadata_tmp)\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \n\u001b[0;32m     61\u001b[0m \u001b[39m# Concatenate raw instances as if they were continuous\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m raw, events \u001b[39m=\u001b[39m mne\u001b[39m.\u001b[39;49mconcatenate_raws(raw_list,\n\u001b[0;32m     63\u001b[0m                                    events_list\u001b[39m=\u001b[39;49mevents_list)\n\u001b[0;32m     64\u001b[0m \u001b[39mdel\u001b[39;00m raw_list\n\u001b[0;32m     66\u001b[0m \u001b[39m# Concatenate metadata tables\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[39m# metadata = pd.concat(metadata_list)\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[39m# metadata.to_csv(op.join(out_path,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     71\u001b[0m \n\u001b[0;32m     72\u001b[0m \u001b[39m# Set reject criteria\u001b[39;00m\n",
      "File \u001b[1;32m<decorator-gen-238>:12\u001b[0m, in \u001b[0;36mconcatenate_raws\u001b[1;34m(raws, preload, events_list, on_mismatch, verbose)\u001b[0m\n",
      "File \u001b[1;32md:\\projects\\WM_GRID\\venv\\lib\\site-packages\\mne\\io\\base.py:2551\u001b[0m, in \u001b[0;36mconcatenate_raws\u001b[1;34m(raws, preload, events_list, on_mismatch, verbose)\u001b[0m\n\u001b[0;32m   2549\u001b[0m     first, last \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m[(r\u001b[39m.\u001b[39mfirst_samp, r\u001b[39m.\u001b[39mlast_samp) \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m raws])\n\u001b[0;32m   2550\u001b[0m     events \u001b[39m=\u001b[39m concatenate_events(events_list, first, last)\n\u001b[1;32m-> 2551\u001b[0m raws[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mappend(raws[\u001b[39m1\u001b[39;49m:], preload)\n\u001b[0;32m   2553\u001b[0m \u001b[39mif\u001b[39;00m events_list \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2554\u001b[0m     \u001b[39mreturn\u001b[39;00m raws[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32md:\\projects\\WM_GRID\\venv\\lib\\site-packages\\mne\\io\\base.py:1667\u001b[0m, in \u001b[0;36mBaseRaw.append\u001b[1;34m(self, raws, preload)\u001b[0m\n\u001b[0;32m   1664\u001b[0m     this_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data\n\u001b[0;32m   1666\u001b[0m \u001b[39m# allocate the buffer\u001b[39;00m\n\u001b[1;32m-> 1667\u001b[0m _data \u001b[39m=\u001b[39m _allocate_data(preload, (nchan, nsamp), this_data\u001b[39m.\u001b[39;49mdtype)\n\u001b[0;32m   1668\u001b[0m _data[:, \u001b[39m0\u001b[39m:c_ns[\u001b[39m0\u001b[39m]] \u001b[39m=\u001b[39m this_data\n\u001b[0;32m   1670\u001b[0m \u001b[39mfor\u001b[39;00m ri \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(raws)):\n",
      "File \u001b[1;32md:\\projects\\WM_GRID\\venv\\lib\\site-packages\\mne\\io\\base.py:1994\u001b[0m, in \u001b[0;36m_allocate_data\u001b[1;34m(preload, shape, dtype)\u001b[0m\n\u001b[0;32m   1992\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Allocate data in memory or in memmap for preloading.\"\"\"\u001b[39;00m\n\u001b[0;32m   1993\u001b[0m \u001b[39mif\u001b[39;00m preload \u001b[39min\u001b[39;00m (\u001b[39mNone\u001b[39;00m, \u001b[39mTrue\u001b[39;00m):  \u001b[39m# None comes from _read_segment\u001b[39;00m\n\u001b[1;32m-> 1994\u001b[0m     data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mzeros(shape, dtype)\n\u001b[0;32m   1995\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1996\u001b[0m     _validate_type(preload, \u001b[39m'\u001b[39m\u001b[39mpath-like\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpreload\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 22.4 GiB for an array with shape (310, 9688000) and data type float64"
     ]
    }
   ],
   "source": [
    "    subject_id=subject_list[0]\n",
    "    file_exts = ['%sa01',\n",
    "                     '%sa02',\n",
    "                     '%sa03',\n",
    "                     '%sa04',\n",
    "                     '%sa05',\n",
    "                     '%sa06',\n",
    "                     '%sb07',\n",
    "                     '%sb08',\n",
    "                     '%sb09',\n",
    "                     '%sb10',\n",
    "                     '%sb11',\n",
    "                     '%sb12']#,\n",
    "\n",
    "    file_names = [f % (subject_id) for f in file_exts]\n",
    "\n",
    "\n",
    "    # =============================================================================\n",
    "    # GENERAL SETTINGS\n",
    "    # =============================================================================\n",
    "\n",
    "    # Set out_path folder or create it if it doesn't exist\n",
    "    out_path = op.join(data_path, \"out_path\")\n",
    "    if not op.exists(out_path):\n",
    "        os.mkdir(out_path)\n",
    "\n",
    "\n",
    "    # =============================================================================\n",
    "    # MAXWELL FILTERING SETTINGS\n",
    "    # =============================================================================\n",
    "\n",
    "    # Set filtering method\n",
    "    method='sss'\n",
    "    if method == 'tsss':\n",
    "        st_duration = 10\n",
    "    else:\n",
    "        st_duration = None\n",
    "\n",
    "\n",
    "    # =============================================================================\n",
    "    # FILTERING AND DOWNSAMPLING SETTINGS\n",
    "    # =============================================================================\n",
    "\n",
    "    # Filter and resampling params\n",
    "    l_freq = 1\n",
    "    h_freq = 40\n",
    "    sfreq = 200\n",
    "\n",
    "\n",
    "    # =============================================================================\n",
    "    # EPOCHING SETTINGS\n",
    "    # =============================================================================\n",
    "\n",
    "    # Set timewindow\n",
    "    tmin = -0.5\n",
    "    tmax = 8.1\n",
    "\n",
    "    # Epoch rejection criteria\n",
    "    reject_meg = dict(grad=4000e-13,    # T / m (gradiometers)\n",
    "                      mag=4e-12         # T (magnetometers)\n",
    "                      )\n",
    "\n",
    "    # Set epoching event ids\n",
    "\n",
    "    events_id = 101\n",
    "\n",
    "\n",
    "\n",
    "    # =============================================================================\n",
    "    # ICA SETTINGS\n",
    "    # =============================================================================\n",
    "\n",
    "    ica_method = 'fastica'\n",
    "    n_components = 0.99\n",
    "    max_iter = 800\n",
    "    random_state = 1688\n",
    "\n",
    "\n",
    "    # =============================================================================\n",
    "    #  FACTOR AND CONDITIONS OF INTEREST\n",
    "    # =============================================================================\n",
    "\n",
    "    \n",
    "    # factor = 'Category'\n",
    "    # conditions = ['face', 'object', 'letter', 'false']\n",
    "\n",
    "        # factor = 'Relevance'\n",
    "        # conditions = ['Relevant target','Relevant non-target','Irrelevant']\n",
    "\n",
    "\n",
    "    # =============================================================================\n",
    "    # TIME-FREQUENCY REPRESENTATION SETTINGS\n",
    "    # =============================================================================\n",
    "\n",
    "    baseline_w = [-0.5, -0.25]     #only for plotting\n",
    "    freq_band = 'both' #can be 'low', 'high' or 'both'\n",
    "\n",
    "    # =============================================================================\n",
    "    # RUN\n",
    "    # =============================================================================\n",
    "\n",
    "    # meg_ica_eog,meg_ica_ecg = ica_choice[0],ica_choice[1]\n",
    "    \n",
    "    #apply_ica(meg_ica_eog = meg_ica_eog,\n",
    "    #          meg_ica_ecg = meg_ica_ecg)\n",
    "    run_epochs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 50 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 50.00 Hz\n",
      "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
      "- Filter length: 3301 samples (3.301 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 306 out of 306 | elapsed:    7.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "60 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 60 events and 8601 original time points ...\n",
      "4 bad epochs dropped\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Number of events</th>\n",
       "        <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Events</th>\n",
       "        \n",
       "        <td>101: 56</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Time range</th>\n",
       "        <td>-0.500 â€“ 8.100 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Baseline</th>\n",
       "        <td>off</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Epochs |  56 events (all good), -0.5 - 8.1 sec, baseline off, ~6.5 MB, data not loaded,\n",
       " '101': 56>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "        raw_fname_in = op.join(out_path,\n",
    "                               file_names[2] + '_ica.fif')\n",
    "        raw_tmp = mne.io.read_raw_fif(\n",
    "            raw_fname_in, \n",
    "            preload=True, \n",
    "            verbose='error')\n",
    "        raw_tmp.filter(1, 50)\n",
    "        # Read events\n",
    "        events_tmp = mne.read_events(op.join(out_path,\n",
    "                                             file_names[2] + '-eve.fif'))                           \n",
    "        # Read metadata\n",
    "        # metadata_tmp = pd.read_csv(op.join(out_path,\n",
    "        #                                   file_name + '-meta.csv'))\n",
    "        \n",
    "        # Append read data to list\n",
    "\n",
    "        # metadata_list.append(metadata_tmp)\n",
    "\n",
    "    # Concatenate raw instances as if they were continuous\n",
    "    \n",
    "    \n",
    "    # Concatenate metadata tables\n",
    "    # metadata = pd.concat(metadata_list)\n",
    "    # metadata.to_csv(op.join(out_path,\n",
    "    #                    file_name[0:14] + 'ALL-meta.csv'),\n",
    "    #                index=False)\n",
    "    \n",
    "    # Set reject criteria\n",
    "        reject_meg = dict(grad=5000e-13,    # T / m (gradiometers)\n",
    "                        mag=5e-12         # T (magnetometers)\n",
    "                        )\n",
    "        reject = reject_meg\n",
    "        events_id=101\n",
    "        tmin = -0.5\n",
    "        tmax = 8.1\n",
    "    \n",
    "    # Select sensor types\n",
    "    #picks = mne.pick_types(raw.info,\n",
    "    #                       meg = True,\n",
    "    #                       stim = True)\n",
    "    \n",
    "    # Epoch raw data\n",
    "        picks = mne.pick_types(raw_tmp.info,\n",
    "                            meg = True)\n",
    "        epochs = mne.Epochs(raw_tmp,\n",
    "                        events_tmp, \n",
    "                        events_id,\n",
    "                        tmin, tmax,\n",
    "                        baseline=None,\n",
    "                        proj=True,\n",
    "                        picks=picks,\n",
    "                        detrend=1,\n",
    "                        reject=reject,\n",
    "                        reject_by_annotation=True,\n",
    "                        verbose=True)\n",
    "    \n",
    "    # epochs.metadata = metadata\n",
    "    \n",
    "\n",
    "    \n",
    "    # Add metadata\n",
    "    # epochs.metadata = metadata\n",
    "    \n",
    "    # Drop bad epochs based on peak-to-peak magnitude\n",
    "        epochs.drop_bad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_tmp.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name='mg99a01'\n",
    "data_path =  'D:\\projects\\WM_GRID\\DATA\\mg99a'\n",
    "raw_fname_in = op.join(data_path,\n",
    "                        file_name + '.fif')\n",
    "raw = mne.io.read_raw_fif(\n",
    "            raw_fname_in, \n",
    "            preload=True, \n",
    "            verbose='error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.info['dev_head_t'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name='mg99a01'\n",
    "data_path =  'D:\\projects\\WM_GRID\\DATA\\mg99a'\n",
    "out_path = op.join(data_path, \"out_path\")\n",
    "raw_fname_in = op.join(out_path,\n",
    "                        file_name + '_sss.fif')\n",
    "raw = mne.io.read_raw_fif(\n",
    "            raw_fname_in, \n",
    "            preload=True, \n",
    "            verbose='error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.info['dev_head_t'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name='mg99a02'\n",
    "data_path =  'D:\\projects\\WM_GRID\\DATA\\mg99a'\n",
    "out_path = op.join(data_path)\n",
    "raw_fname_in = op.join(out_path,\n",
    "                        file_name + '.fif')\n",
    "raw = mne.io.read_raw_fif(\n",
    "            raw_fname_in, \n",
    "            preload=True, \n",
    "            verbose='error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.info['dev_head_t'] "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
