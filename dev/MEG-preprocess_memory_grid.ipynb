{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as op\n",
    "import os\n",
    "# import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from fpdf import FPDF  \n",
    "\n",
    "import mne\n",
    "from mne.preprocessing import find_bad_channels_maxwell\n",
    "import matplotlib.pyplot as plt\n",
    "# from mne.time_frequency import psd_multitaper\n",
    "from mne.preprocessing import annotate_muscle_zscore\n",
    "from mne.preprocessing import ICA\n",
    "from mne.preprocessing import read_ica\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path =  'D:\\projects\\WM_GRID\\DATA\\mg99a'\n",
    "# cal_path = 'D:\\projects\\WM_GRID\\DATA\\ctc'\n",
    "# sss_path = 'D:\\projects\\WM_GRID\\DATA\\sss'\n",
    "\n",
    "data_path =  '/data/pt_02783/memory_grid/rawdir/mg99a'\n",
    "cal_path = 'data/pt_02783/ctc'\n",
    "sss_path = 'data/pt_02783/sss'\n",
    "\n",
    "\n",
    "subject_list = ['mg99']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load config.py\n",
    "\"\"\"\n",
    "===========\n",
    "Config file\n",
    "===========\n",
    "\n",
    "Configurate the parameters of the study.\n",
    "\"\"\"\n",
    "for subject_id in subject_list[:1]:\n",
    "\n",
    "    # =============================================================================\n",
    "    # SESSION-SPECIFIC SETTINGS\n",
    "    # =============================================================================\n",
    "\n",
    "    # Set filename based on experiment number\n",
    "\n",
    "    file_exts = ['%sa01',\n",
    "                     '%sa02',\n",
    "                     '%sa03',\n",
    "                     '%sa04',\n",
    "                     '%sa05',\n",
    "                     '%sa06',\n",
    "                     '%sb07',\n",
    "                     '%sb08',\n",
    "                     '%sb09',\n",
    "                     '%sb10',\n",
    "                     '%sb11',\n",
    "                     '%sb12']#,\n",
    "\n",
    "    file_names = [f % (subject_id) for f in file_exts]\n",
    "\n",
    "\n",
    "    # =============================================================================\n",
    "    # GENERAL SETTINGS\n",
    "    # =============================================================================\n",
    "\n",
    "    # Set out_path folder or create it if it doesn't exist\n",
    "    out_path = op.join(data_path, \"out_path\")\n",
    "    if not op.exists(out_path):\n",
    "        os.mkdir(out_path)\n",
    "\n",
    "    # =============================================================================\n",
    "    # MAXWELL FILTERING SETTINGS\n",
    "    # =============================================================================\n",
    "\n",
    "    # Set filtering method\n",
    "    method='sss'\n",
    "    if method == 'tsss':\n",
    "        st_duration = 10\n",
    "    else:\n",
    "        st_duration = None\n",
    "\n",
    "\n",
    "    # =============================================================================\n",
    "    # FILTERING AND DOWNSAMPLING SETTINGS\n",
    "    # =============================================================================\n",
    "\n",
    "    # Filter and resampling params\n",
    "    l_freq = 1\n",
    "    h_freq = 40\n",
    "    sfreq = 200\n",
    "\n",
    "\n",
    "    # =============================================================================\n",
    "    # ICA SETTINGS\n",
    "    # =============================================================================\n",
    "\n",
    "    ica_method = 'fastica'\n",
    "    n_components = 0.99\n",
    "    max_iter = 800\n",
    "    random_state = 1688\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load 01-maxwell_filtering.py\n",
    "\"\"\"\n",
    "===================================\n",
    "01. Maxwell filter using MNE-python\n",
    "===================================\n",
    "\n",
    "The data are Maxwell filtered using tSSS/SSS.\n",
    "\n",
    "It is critical to mark bad channels before Maxwell filtering.\n",
    "\n",
    "Open issues:\n",
    "    1. SSS or tSSS? -> Consult Alex G.?\n",
    "    \n",
    "\"\"\"  # noqa: E501\n",
    "\n",
    "\n",
    "def run_maxwell_filter(method = 'sss'):\n",
    "    # stdout_obj = sys.stdout                 # store original stdout \n",
    "    # sys.stdout = open(op.join(out_path,     # open log file\n",
    "    # os.path.basename(__file__) + \"_%s.txt\" % (site_id+subject_id)),'w')\n",
    "    \n",
    "    # Load the fine calibration file (which encodes site-specific information \n",
    "    # about sensor orientation and calibration) as well as a crosstalk \n",
    "    # compensation file (which reduces interference between Elekta’s co-located\n",
    "    # magnetometer and paired gradiometer sensor units)\n",
    "    crosstalk_file = op.join(cal_path, \"ct_sparse.fif\")\n",
    "    fine_cal_file = op.join(sss_path, \"sss_cal.dat\")\n",
    "\n",
    "    # Create empty dataframe for bad channel list\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    # Prepare PDF report\n",
    "    pdf = FPDF(orientation=\"P\", unit=\"mm\", format=\"A4\")\n",
    "    \n",
    "    print(\"Processing subject: %s\" % subject_id)\n",
    "    run = 0\n",
    "    for file_name in file_names:\n",
    "        run = run + 1\n",
    "        print(\"  File: %s\" % file_name)\n",
    "        \n",
    "        # Read raw data\n",
    "        raw_fname_in = op.join(data_path, file_name + '.fif')\n",
    "        raw = mne.io.read_raw_fif(\n",
    "            raw_fname_in,\n",
    "            allow_maxshield=True,\n",
    "            preload=False,\n",
    "            verbose=True)\n",
    "        \n",
    "        # Detect bad channels\n",
    "        raw.info['bads'] = []\n",
    "        raw_check = raw.copy()\n",
    "        auto_noisy_chs, auto_flat_chs, auto_scores = find_bad_channels_maxwell(\n",
    "            raw_check, \n",
    "            cross_talk=crosstalk_file, \n",
    "            calibration=fine_cal_file,\n",
    "            return_scores=True,\n",
    "            verbose=True)\n",
    "        raw.info['bads'].extend(auto_noisy_chs + auto_flat_chs)\n",
    "        \n",
    "        # Append bad channels to the list \n",
    "        df = df.append({'run': run,\n",
    "                        'noisy': auto_noisy_chs, \n",
    "                        'flat': auto_flat_chs},\n",
    "                        ignore_index=True)        \n",
    "        \n",
    "        # Visualize the scoring used to classify channels as noisy or flat\n",
    "        ch_type = 'grad'\n",
    "        fig = viz_badch_scores(auto_scores, ch_type)\n",
    "        fname_fig = op.join(out_path,\n",
    "                            \"01_r%s_badchannels_%sscore.png\" % (run,ch_type))\n",
    "        fig.savefig(fname_fig)\n",
    "        plt.close()\n",
    "        ch_type = 'mag'\n",
    "        fig = viz_badch_scores(auto_scores, ch_type)\n",
    "        fname_fig = op.join(out_path,\n",
    "                            \"01_r%s_badchannels_%sscore.png\" % (run,ch_type))\n",
    "        fig.savefig(fname_fig)\n",
    "        plt.close()\n",
    "        \n",
    "        # Fix Elekta magnetometer coil types\n",
    "        raw.fix_mag_coil_types()\n",
    "        # realign\n",
    "        file_name_ref=file_names[0]\n",
    "        raw_ref_fname_in = op.join(data_path, file_name_ref + '.fif')\n",
    "        raw_ref = mne.io.read_raw_fif(raw_ref_fname_in,\n",
    "            allow_maxshield=True,\n",
    "            preload=False,\n",
    "            verbose=True)\n",
    "        dev_head_t_ref = raw_ref.info['dev_head_t']\n",
    "        \n",
    "        # Perform tSSS/SSS and Maxwell filtering\n",
    "        raw_sss = mne.preprocessing.maxwell_filter(\n",
    "            raw,\n",
    "            origin='auto',\n",
    "            cross_talk=crosstalk_file,\n",
    "            calibration=fine_cal_file,\n",
    "            st_duration=st_duration,\n",
    "            coord_frame='head',\n",
    "            destination=dev_head_t_ref,\n",
    "            #coord_frame=\"meg\", #only for empy room, comment it if using HPI\n",
    "            verbose=True)\n",
    "        \n",
    "        # Show original and filtered signals\n",
    "        fig = raw.copy().pick(['meg']).plot(duration=5,\n",
    "                                            start=100,\n",
    "                                            butterfly=True)        \n",
    "        fname_fig = op.join(out_path,\n",
    "                            '01_r%s_plotraw.png' % run)\n",
    "        fig.savefig(fname_fig)\n",
    "        plt.close()\n",
    "        fig = raw_sss.copy().pick(['meg']).plot(duration=5,\n",
    "                                                start=100,\n",
    "                                                butterfly=True)\n",
    "        fname_fig = op.join(out_path,\n",
    "                            '01_r%s_plotraw%s.png' % (run,method))\n",
    "        fig.savefig(fname_fig)\n",
    "        plt.close()\n",
    "        \n",
    "        # Show original and filtered power\n",
    "        fig1 = raw.plot_psd(picks = ['meg'],fmin = 1,fmax = 100)\n",
    "        fname_fig1 = op.join(out_path,\n",
    "                            '01_r%s_plot_psd_raw100.png' % run)\n",
    "        fig1.savefig(fname_fig1)\n",
    "        plt.close()\n",
    "        fig2 = raw_sss.plot_psd(picks = ['meg'],fmin = 1,fmax = 100)\n",
    "        fname_fig2 = op.join(out_path,\n",
    "                            '01_r%s_plot_psd_raw100%s.png' % (run,method))\n",
    "        fig2.savefig(fname_fig2)\n",
    "        plt.close()\n",
    "        \n",
    "        '''\n",
    "        # Add figures to report\n",
    "        pdf.add_page()\n",
    "        pdf.set_font('helvetica', 'B', 16)\n",
    "        pdf.cell(0, 10, file_name)\n",
    "        pdf.ln(20)\n",
    "        pdf.set_font('helvetica', 'B', 12)\n",
    "        pdf.cell(0, 10, 'Power Spectrum of Raw MEG Data', 'B', ln=1)\n",
    "        pdf.image(fname_fig1, 0, 45, pdf.epw)\n",
    "        pdf.ln(120)\n",
    "        pdf.cell(0, 10, 'Power Spectrum of Filtered MEG Data', 'B', ln=1)\n",
    "        pdf.image(fname_fig2, 0, 175, pdf.epw)\n",
    "        '''\n",
    "        # Save filtered data\n",
    "        fname_out = op.join(out_path,\n",
    "                            file_name + '_' + method + '.fif')\n",
    "        raw_sss.save(fname_out, overwrite=True)\n",
    "        \n",
    "    # Save bad channel list\n",
    "    df.to_csv(op.join(out_path,\n",
    "                      '01_rAll_meg_badch_list.csv'),\n",
    "              index=False)\n",
    "    \n",
    "    # Save report\n",
    "    # pdf.output(op.join(out_path,\n",
    "    #                  'run_maxwell_filter' + '-report.pdf'))\n",
    "    \n",
    "    # sys.stdout.close()      # close log file\n",
    "    # sys.stdout = stdout_obj # restore command prompt\n",
    "\n",
    "\n",
    "def viz_badch_scores(auto_scores, ch_type):\n",
    "    fig, ax = plt.subplots(1, 4, figsize=(12, 8))\n",
    "    fig.suptitle(f'Automated noisy/flat channel detection: {ch_type}',\n",
    "                  fontsize=16, fontweight='bold')\n",
    "    \n",
    "    #### Noisy channels ####\n",
    "    ch_subset = auto_scores['ch_types'] == ch_type\n",
    "    ch_names = auto_scores['ch_names'][ch_subset]\n",
    "    scores = auto_scores['scores_noisy'][ch_subset]\n",
    "    limits = auto_scores['limits_noisy'][ch_subset]\n",
    "    bins = auto_scores['bins']  #the windows that were evaluated\n",
    "    \n",
    "    # Label each segment by its start and stop time (3 digits / 1 ms precision)\n",
    "    bin_labels = [f'{start:3.3f} – {stop:3.3f}' \n",
    "                  for start, stop in bins]\n",
    "    \n",
    "    # Store  data in DataFrame\n",
    "    data_to_plot = pd.DataFrame(data=scores,\n",
    "                                columns=pd.Index(bin_labels, name='Time (s)'),\n",
    "                                index=pd.Index(ch_names, name='Channel'))\n",
    "    \n",
    "    # First, plot the raw scores\n",
    "    sns.heatmap(data=data_to_plot, \n",
    "                cmap='Reds', \n",
    "                cbar=False,\n",
    "                # cbar_kws=dict(label='Score'),\n",
    "                ax=ax[0])\n",
    "    [ax[0].axvline(x, ls='dashed', lw=0.25, dashes=(25, 15), color='gray')\n",
    "        for x in range(1, len(bins))]\n",
    "    ax[0].set_title('Noisy: All Scores', fontweight='bold')\n",
    "\n",
    "    # Second, highlight segments that exceeded the 'noisy' limit\n",
    "    sns.heatmap(data=data_to_plot,\n",
    "                vmin=np.nanmin(limits),\n",
    "                cmap='Reds', \n",
    "                cbar=True, \n",
    "                # cbar_kws=dict(label='Score'), \n",
    "                ax=ax[1])\n",
    "    [ax[1].axvline(x, ls='dashed', lw=0.25, dashes=(25, 15), color='gray')\n",
    "        for x in range(1, len(bins))]\n",
    "    ax[1].set_title('Noisy: Scores > Limit', fontweight='bold')\n",
    "    \n",
    "    #### Flat channels ####\n",
    "    ch_subset = auto_scores['ch_types'] == ch_type\n",
    "    ch_names = auto_scores['ch_names'][ch_subset]\n",
    "    scores = auto_scores['scores_flat'][ch_subset]\n",
    "    limits = auto_scores['limits_flat'][ch_subset]\n",
    "    bins = auto_scores['bins']  #the windows that were evaluated\n",
    "    \n",
    "    # Label each segment by its start and stop time (3 digits / 1 ms precision)\n",
    "    bin_labels = [f'{start:3.3f} – {stop:3.3f}' \n",
    "                  for start, stop in bins]\n",
    "    \n",
    "    # Store  data in DataFrame\n",
    "    data_to_plot = pd.DataFrame(data=scores,\n",
    "                                columns=pd.Index(bin_labels, name='Time (s)'),\n",
    "                                index=pd.Index(ch_names, name='Channel'))\n",
    "    \n",
    "    # First, plot the raw scores\n",
    "    sns.heatmap(data=data_to_plot, \n",
    "                cmap='Reds', \n",
    "                cbar=False,\n",
    "                # cbar_kws=dict(label='Score'),\n",
    "                ax=ax[2])\n",
    "    [ax[2].axvline(x, ls='dashed', lw=0.25, dashes=(25, 15), color='gray')\n",
    "        for x in range(1, len(bins))]\n",
    "    ax[2].set_title('Flat: All Scores', fontweight='bold')\n",
    "\n",
    "    # Second, highlight segments that exceeded the 'noisy' limit\n",
    "    sns.heatmap(data=data_to_plot,\n",
    "                vmax=np.nanmax(limits),\n",
    "                cmap='Reds', \n",
    "                cbar=True,\n",
    "                # cbar_kws=dict(label='Score'), \n",
    "                ax=ax[3])\n",
    "    [ax[3].axvline(x, ls='dashed', lw=0.25, dashes=(25, 15), color='gray')\n",
    "        for x in range(1, len(bins))]\n",
    "    ax[3].set_title('Flat: Scores > Limit', fontweight='bold')\n",
    "    \n",
    "    # Fit figure title to not overlap with the subplots\n",
    "    fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load 03-artifact_annotation.py\n",
    "\"\"\"\n",
    "===========================\n",
    "03. Artifact annotation\n",
    "===========================\n",
    "\n",
    "Detect and note ocular and muscle artifacts\n",
    "\n",
    "Open issues:\n",
    "    1. Eye-link annot?\n",
    "    -> Ling will develop it\n",
    "\n",
    "\"\"\"  # noqa: E501\n",
    "\n",
    "\n",
    "def artifact_annotation():  \n",
    "    # stdout_obj = sys.stdout                 # store original stdout \n",
    "    # sys.stdout = open(op.join(out_path,     # open log file\n",
    "                              # os.path.basename(__file__) + \"_%s.txt\" % (site_id+subject_id)),'w')\n",
    "    \n",
    "    # Prepare PDF report\n",
    "    pdf = FPDF(orientation=\"P\", unit=\"mm\", format=\"A4\")    \n",
    "    print(\"Processing subject: %s\" % subject_id)\n",
    "    run = 0\n",
    "    for file_name in file_names:\n",
    "        run = run + 1\n",
    "        print(\"  File: %s\" % file_name)\n",
    "        \n",
    "        # Read raw data\n",
    "        raw_fname_in = op.join(out_path,\n",
    "                               file_name + '_sss.fif')\n",
    "        raw = mne.io.read_raw_fif(\n",
    "            raw_fname_in, \n",
    "            preload=True, \n",
    "            verbose='error')\n",
    "        \n",
    "        # Create empty annotations list\n",
    "        annot_artifact = mne.Annotations(onset=[], \n",
    "                                         duration=[],\n",
    "                                         description=[])\n",
    "        \n",
    "        ###########################\n",
    "        # Detect ocular artifacts #\n",
    "        ###########################\n",
    "        \n",
    "        # Resetting the EOG channel\n",
    "        \"\"\"\n",
    "        eog_ch = raw.copy().pick_types(meg=False, eeg=False, eog=True)\n",
    "        if len(eog_ch.ch_names) < 2:\n",
    "            raw.set_channel_types({'BIO002':'eog'})\n",
    "            raw.rename_channels({'BIO002': 'EOG002'})\n",
    "            \n",
    "            # Find EOG events\n",
    "            eog_events = mne.preprocessing.find_eog_events(raw)\n",
    "            onsets = (eog_events[:, 0] - raw.first_samp) / raw.info['sfreq'] - 0.25\n",
    "            durations = [0.5] * len(eog_events)\n",
    "            descriptions = ['Blink'] * len(eog_events)\n",
    "            \n",
    "            # Annotate events\n",
    "            annot_blink = mne.Annotations(\n",
    "                onsets, \n",
    "                durations,\n",
    "                descriptions)\n",
    "                # orig_time=raw.info['meas_date'])\n",
    "            \n",
    "            # Add blinks to annotations list\n",
    "            annot_artifact = annot_artifact + annot_blink\n",
    "            \n",
    "            # Plot blink with EEG data\n",
    "            eeg_picks = mne.pick_types(raw.info, \n",
    "                                      meg=False,\n",
    "                                      eeg=True,\n",
    "                                      eog=True)\n",
    "#             print(eog_events)\n",
    "            fig = raw.plot(events=eog_events,\n",
    "                          start=400,  ### correction: 800 -> 400 no element if too high\n",
    "                          order=eeg_picks)\n",
    "            fname_fig = op.join(out_path,\n",
    "                               \"03_r%s_artifact_blink.png\" % run)\n",
    "            fig.savefig(fname_fig)\n",
    "            plt.close()\n",
    "        \"\"\"\n",
    "        ###########################\n",
    "        # Detect muscle artifacts #\n",
    "        ###########################\n",
    "        \n",
    "        # Notch filter\n",
    "        raw_muscle = raw.copy().notch_filter([50, 100])\n",
    "        \n",
    "        # The threshold is data dependent, check the optimal threshold by plotting\n",
    "        # ``scores_muscle``.\n",
    "        threshold_muscle = 5  # z-score\n",
    "        \n",
    "        # Choose one channel type, if there are axial gradiometers and magnetometers,\n",
    "        # select magnetometers as they are more sensitive to muscle activity.\n",
    "        annot_muscle, scores_muscle = annotate_muscle_zscore(\n",
    "            raw_muscle, \n",
    "            ch_type=\"mag\", \n",
    "            threshold=threshold_muscle, \n",
    "            min_length_good=0.2,\n",
    "            filter_freq=[110, 140])\n",
    "        \n",
    "        # Add muscle artifacts to annotations list\n",
    "        annot_artifact = annot_artifact + annot_muscle\n",
    "        \n",
    "        # Plot muscle z-scores across recording\n",
    "        fig1, ax = plt.subplots()\n",
    "        ax.plot(raw.times, scores_muscle)\n",
    "        ax.axhline(y=threshold_muscle, color='r')\n",
    "        ax.set(xlabel='time, (s)', ylabel='zscore', title='Muscle activity')\n",
    "        fname_fig1 = op.join(out_path,\n",
    "                            \"03_r%s_artifact_muscle.png\" % run)\n",
    "        fig1.savefig(fname_fig1)\n",
    "        plt.close()\n",
    "        \n",
    "        '''\n",
    "        # Add figure to report\n",
    "        pdf.add_page()\n",
    "        pdf.set_font('helvetica', 'B', 16)\n",
    "        pdf.cell(0, 10, file_name)\n",
    "        pdf.ln(20)\n",
    "        pdf.set_font('helvetica', 'B', 12)\n",
    "        pdf.cell(0, 10, 'Muscle artifact power', 'B', ln=1)\n",
    "        pdf.image(fname_fig1, 0, 45, pdf.epw)\n",
    "        '''\n",
    "        ###########################\n",
    "        \n",
    "        # Set annotations\n",
    "        raw.set_annotations(annot_artifact)\n",
    "        \n",
    "        # View raw with annotations\n",
    "        channel_picks = mne.pick_types(raw.info, \n",
    "                                       meg='mag', eog=True)\n",
    "        fig2 = raw.plot(duration=50,\n",
    "                       start=100,\n",
    "                       order=channel_picks)\n",
    "        fname_fig2 = op.join(out_path,\n",
    "                            \"03_r%s_artifact_annot.png\" % run)\n",
    "        fig2.savefig(fname_fig2)\n",
    "        plt.close()\n",
    "        \n",
    "        '''\n",
    "        # Add figures to report\n",
    "        pdf.ln(120)\n",
    "        pdf.cell(0, 10, 'Data and annotations', 'B', ln=1)\n",
    "        pdf.image(fname_fig2, 0, 175, pdf.epw)\n",
    "        '''\n",
    "        \n",
    "        # Save data with annotated artifacts\n",
    "        fname_out = op.join(out_path,\n",
    "                            file_name + '_artif.fif')                            \n",
    "        raw.save(fname_out, overwrite=True)\n",
    "    \n",
    "    # Save report\n",
    "    pdf.output(op.join(out_path,\n",
    "                       'artifact_annotation' + '-report.pdf'))\n",
    "    \n",
    "    # sys.stdout.close()      # close log file\n",
    "    # sys.stdout = stdout_obj # restore command prompt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load 04-extract_events.py\n",
    "\"\"\"\n",
    "===================\n",
    "04. Extract events\n",
    "===================\n",
    "\n",
    "Extract events from the stimulus channel\n",
    "\n",
    "Open issues:\n",
    "    - metadata for exp 2 needs to be created\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def run_events():\n",
    "    \n",
    "    # stdout_obj = sys.stdout                 # store original stdout \n",
    "    # sys.stdout = open(op.join(out_path,     # open log file\n",
    "                              # os.path.basename(__file__) + \"_%s.txt\" % (site_id+subject_id)),'w')\n",
    "    \n",
    "    # Prepare PDF report\n",
    "    pdf = FPDF(orientation=\"P\", unit=\"mm\", format=\"A4\")\n",
    "\n",
    "    print(\"Processing subject: %s\" % subject_id)\n",
    "    run = 0\n",
    "    for file_name in file_names:\n",
    "        run = run + 1\n",
    "        print(\"  File: %s\" % file_name)\n",
    "        \n",
    "        # Read raw data\n",
    "        run_fname = op.join(data_path,\n",
    "                            file_name + '.fif')\n",
    "        raw = mne.io.read_raw_fif(\n",
    "            run_fname,\n",
    "            allow_maxshield=True,\n",
    "            verbose=True)\n",
    "        \n",
    "        ###############\n",
    "        # Read events #\n",
    "        ###############\n",
    "    \n",
    "        \n",
    "        # Find all events\n",
    "        events = mne.find_events(raw,\n",
    "                                 stim_channel='STI101',\n",
    "                                 consecutive = True,\n",
    "                                 min_duration=0.001001,\n",
    "                                 mask = 65280,\n",
    "                                 mask_type = 'not_and'\n",
    "                                )\n",
    "        events = events[events[:,2] != 255]\n",
    "        \n",
    "        # Concatenate all events\n",
    "        events = np.concatenate([events],axis = 0)\n",
    "        events = events[events[:,0].argsort(),:]\n",
    "        \n",
    "        # Show events\n",
    "        fig = mne.viz.plot_events(events)\n",
    "        fname_fig = op.join(out_path,\n",
    "                            \"04_r%s_events.png\" % run)\n",
    "        fig.savefig(fname_fig)\n",
    "        plt.close(fig)\n",
    "        \n",
    "        '''\n",
    "        # Add figure to report\n",
    "        pdf.add_page()\n",
    "        pdf.set_font('helvetica', 'B', 16)\n",
    "        pdf.cell(0, 10, file_name)\n",
    "        pdf.ln(20)\n",
    "        pdf.set_font('helvetica', 'B', 12)\n",
    "        pdf.cell(0, 10, 'Events', 'B', ln=1)\n",
    "        pdf.image(fname_fig, 0, 45, pdf.epw)\n",
    "        '''\n",
    "        # Save event array\n",
    "        fname_events = op.join(out_path,\n",
    "                               file_name + '-eve.fif')                            \n",
    "        mne.write_events(fname_events, events)\n",
    "        \n",
    "    # Save report\n",
    "    # pdf.output(op.join(out_path,\n",
    "    #                   'run_events' + '-report.pdf'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load 05-run_ica.py\n",
    "\"\"\"\n",
    "===========\n",
    "05. Run ICA\n",
    "===========\n",
    "\n",
    "Open issues:\n",
    "    1. why the EEG-specific ICA gives only a few components?\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def run_ica(max_iter = 100, n_components = 0.99, random_state = 1):\n",
    "    \n",
    "    # stdout_obj = sys.stdout                 # store original stdout \n",
    "    # sys.stdout = open(op.join(out_path,     # open log file\n",
    "    #                           os.path.basename(__file__) + \"_%s.txt\" % (site_id+subject_id)),'w')\n",
    "    print('\\n\\n\\n\\n\\n#######################################################################################')\n",
    "    print(\"Processing subject: %s\" % subject_id)\n",
    "    run = 0\n",
    "    for file_name in file_names:\n",
    "        run = run + 1\n",
    "        print(\"  File: %s\" % file_name)\n",
    "        \n",
    "        # Read raw data\n",
    "        raw_fname_in = op.join(out_path,\n",
    "                               file_name + '_artif.fif')\n",
    "        raw = mne.io.read_raw_fif(\n",
    "            raw_fname_in, \n",
    "            preload=True, \n",
    "            verbose='error')\n",
    "        \n",
    "        # Downsample copy of raw\n",
    "        raw_resmpl = raw.copy().resample(sfreq)\n",
    "            \n",
    "        # Band-pass filter raw copy\n",
    "        raw_resmpl.filter(l_freq, h_freq)\n",
    "            \n",
    "        # Concatenate raw copies\n",
    "        if run == 1:\n",
    "            raw_resmpl_all = mne.io.concatenate_raws([raw_resmpl])\n",
    "        else:\n",
    "            raw_resmpl_all = mne.io.concatenate_raws([raw_resmpl_all, raw_resmpl])\n",
    "        \n",
    "        del raw, raw_resmpl\n",
    "    \n",
    "    ###################\n",
    "    # ICA on MEG data #\n",
    "    ###################\n",
    "    \n",
    "    # Prepare PDF report\n",
    "    pdf = FPDF(orientation=\"P\", unit=\"mm\", format=\"A4\")\n",
    "    \n",
    "    # Define ICA settings\n",
    "    ica = ICA(method=ica_method,\n",
    "              random_state=random_state,\n",
    "              n_components=n_components,\n",
    "              verbose=True)\n",
    "    \n",
    "    # Run ICA on filtered raw data\n",
    "    ica.fit(raw_resmpl_all,\n",
    "            picks='meg',\n",
    "            verbose=True)\n",
    "    \n",
    "    # Plot timecourse of estimated sources\n",
    "    fig = ica.plot_sources(raw_resmpl_all,\n",
    "                           start=100,\n",
    "                           show_scrollbars=False,\n",
    "                           title='ICA_MEG')\n",
    "    \n",
    "    # for i in range(len(fig)):\n",
    "    #     fname_fig = op.join(out_path, \n",
    "    #                         '05_rAll_ica_meg_src%d' % i)\n",
    "    #     fig[i].savefig(fname_fig)\n",
    "    #     plt.close(fig[i])\n",
    "\n",
    "    fname_fig = op.join(out_path, \n",
    "                      \"05_rAll_ica_meg_src.png\")\n",
    "    fig.savefig(fname_fig)\n",
    "    plt.close(fig)\n",
    "    \n",
    "    '''\n",
    "    # Add figure to report\n",
    "    pdf.add_page()\n",
    "    pdf.set_font('helvetica', 'B', 16)\n",
    "    pdf.cell(0, 10, file_names[0][0:13] + ' - MEG')\n",
    "    pdf.ln(20)\n",
    "    pdf.set_font('helvetica', 'B', 12)\n",
    "    pdf.cell(0, 10, 'Timecourse of MEG ICs', 'B', ln=1)\n",
    "    pdf.image(fname_fig, 0, 45, pdf.epw)\n",
    "    '''\n",
    "    # Project mixing matrix on interpolated sensor topography\n",
    "    fig = ica.plot_components(title='ICA_MEG')\n",
    "    for i in range(len(fig)):\n",
    "        fname_fig = op.join(out_path, \n",
    "                            '05_rAll_ica_meg_cmp%d.png' % i)\n",
    "        fig[i].savefig(fname_fig)\n",
    "        plt.close(fig[i])\n",
    "        \n",
    "        '''\n",
    "        # Add figure to report\n",
    "        pdf.add_page()\n",
    "        pdf.set_font('helvetica', 'B', 16)\n",
    "        pdf.cell(0, 10, file_names[0][0:13] + ' - MEG')\n",
    "        pdf.ln(20)\n",
    "        pdf.set_font('helvetica', 'B', 12)\n",
    "        pdf.cell(0, 10, 'Topography of MEG ICs', 'B', ln=1)\n",
    "        pdf.image(fname_fig, 0, 45, pdf.epw)\n",
    "        \n",
    "        '''\n",
    "    # Save files\n",
    "    ica_fname = op.join(out_path,\n",
    "                        file_name[0:14] + 'ALL-ica_meg.fif')\n",
    "    ica.save(ica_fname)\n",
    "    \n",
    "    # Save report\n",
    "    pdf.output(op.join(out_path,\n",
    "                       'run_ica' + '-reportMEG.pdf'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %load config.py\n",
    "\"\"\"\n",
    "===========\n",
    "Config file\n",
    "===========\n",
    "\n",
    "Configurate the parameters of the study.\n",
    "\"\"\"\n",
    "for subject_id in subject_list[:1]:\n",
    "\n",
    "    # =============================================================================\n",
    "    # SESSION-SPECIFIC SETTINGS\n",
    "    # =============================================================================\n",
    "\n",
    "    # Set filename based on experiment number\n",
    "    file_exts = ['%sa01',\n",
    "                     '%sa02',\n",
    "                     '%sa03',\n",
    "                     '%sa04',\n",
    "                     '%sa05',\n",
    "                     '%sa06',\n",
    "                     '%sb07',\n",
    "                     '%sb08',\n",
    "                     '%sb09',\n",
    "                     '%sb10',\n",
    "                     '%sb11',\n",
    "                     '%sb12']\n",
    "\n",
    "    file_names = [f % (subject_id) for f in file_exts]\n",
    "\n",
    "\n",
    "    # =============================================================================\n",
    "    # GENERAL SETTINGS\n",
    "    # =============================================================================\n",
    "\n",
    "    # Set out_path folder or create it if it doesn't exist\n",
    "    out_path = op.join(data_path, \"out_path\")\n",
    "    if not op.exists(out_path):\n",
    "        os.mkdir(out_path)\n",
    "\n",
    "\n",
    "    # =============================================================================\n",
    "    # MAXWELL FILTERING SETTINGS\n",
    "    # =============================================================================\n",
    "\n",
    "    # Set filtering method\n",
    "    method='sss'\n",
    "    if method == 'tsss':\n",
    "        st_duration = 10\n",
    "    else:\n",
    "        st_duration = None\n",
    "\n",
    "\n",
    "    # =============================================================================\n",
    "    # FILTERING AND DOWNSAMPLING SETTINGS\n",
    "    # =============================================================================\n",
    "\n",
    "    # Filter and resampling params\n",
    "    l_freq = 1\n",
    "    h_freq = 40\n",
    "    sfreq = 200\n",
    "\n",
    "\n",
    "    # =============================================================================\n",
    "    # ICA SETTINGS\n",
    "    # =============================================================================\n",
    "\n",
    "    ica_method = 'fastica'\n",
    "    n_components = 0.99\n",
    "    max_iter = 800\n",
    "    random_state = 1688\n",
    "\n",
    "\n",
    "    # =============================================================================\n",
    "    # RUN\n",
    "    # =============================================================================\n",
    "\n",
    "    # run_maxwell_filter(method=method)\n",
    "\n",
    "\n",
    "    # artifact_annotation()\n",
    "\n",
    "    # run_events()\n",
    "    \n",
    "    run_ica(max_iter = max_iter, \n",
    "            n_components = n_components, \n",
    "            random_state = random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load 06-apply_ica.py\n",
    "\"\"\"\n",
    "===============\n",
    "06. Apply ICA\n",
    "===============\n",
    "\n",
    "This relies on the ICAs computed in 05-run_ica.py\n",
    "\n",
    "Open issues:\n",
    "    1. Should we automitaze EOG- and ECG-related ICs detection?\n",
    "    -> up to Ling and Oscar. Do auto and cross-check afterwards\n",
    "    2. Add plots?\n",
    "    -> no\n",
    "    3. How many comps per type should we remove?\n",
    "    -> 1-2 each (if any). 2-5 in total\n",
    "    4. Apply on concatenated data? -> Yes\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "def apply_ica(meg_ica_eog = [], meg_ica_ecg = []):\n",
    "\n",
    "    # Prepare PDF report\n",
    "    pdf = FPDF(orientation=\"P\", unit=\"mm\", format=\"A4\")\n",
    "    \n",
    "    print(\"Processing subject: %s\" % subject_id)\n",
    "    run = 0\n",
    "    for file_name in file_names:\n",
    "        run = run + 1\n",
    "        print(\"  File: %s\" % file_name)\n",
    "        \n",
    "        # Read raw data\n",
    "        raw_fname_in = op.join(out_path,\n",
    "                               file_name + '_artif.fif')\n",
    "        raw = mne.io.read_raw_fif(\n",
    "            raw_fname_in, \n",
    "            preload=True, \n",
    "            verbose='error')\n",
    "        \n",
    "        # Show original signal\n",
    "\n",
    "        chs = ['MEG0311', 'MEG0121', 'MEG1211', 'MEG1411', 'EOG001','EOG002']\n",
    "        chan_idxs = [raw.ch_names.index(ch) for ch in chs]\n",
    "        fig1 = raw.plot(order=chan_idxs,\n",
    "                       duration=50,\n",
    "                       start=100)        \n",
    "        fname_fig1 = op.join(out_path,\n",
    "                            '06_r%s_ica_raw0.png' % run)\n",
    "        fig1.savefig(fname_fig1)\n",
    "        plt.close()\n",
    "        \n",
    "        '''\n",
    "        # Add figure to report\n",
    "        pdf.add_page()\n",
    "        pdf.set_font('helvetica', 'B', 16)\n",
    "        pdf.cell(0, 10, file_name)\n",
    "        pdf.ln(20)\n",
    "        pdf.set_font('helvetica', 'B', 12)\n",
    "        pdf.cell(0, 10, 'Timecourse of input data', 'B', ln=1)\n",
    "        pdf.image(fname_fig1, 0, 45, pdf.epw)\n",
    "        '''\n",
    "        ###################\n",
    "        # ICA on MEG data #\n",
    "        ###################\n",
    "        \n",
    "        if [meg_ica_eog + meg_ica_ecg] != []:\n",
    "            \n",
    "            # Restore ICA solution from fif file\n",
    "            ica_meg_fname = op.join(out_path,\n",
    "                                file_name[0:14] + 'ALL-ica_meg.fif')\n",
    "            ica_meg = read_ica(ica_meg_fname)\n",
    "            \n",
    "            # Select EOG- and ECG-related components for exclusion\n",
    "            ica_meg.exclude.extend(meg_ica_eog + meg_ica_ecg)\n",
    "            \n",
    "            # # Plot excluded ICs\n",
    "            # if meg_ica_eog != []:\n",
    "            #     # Display component properties\n",
    "            #     fig = ica.plot_properties(raw, \n",
    "            #                               picks=meg_ica_eog)\n",
    "            #     for i in range(len(fig)):\n",
    "            #         fname_fig = op.join(out_path, \n",
    "            #                             \"04_r%s_ica_meg_eog%d.png\" % (run,i))\n",
    "            #         fig[i].savefig(fname_fig)\n",
    "            #         plt.close(fig[i])\n",
    "            # if meg_ica_ecg != []:\n",
    "            #     # Display component properties\n",
    "            #     fig = ica.plot_properties(raw, \n",
    "            #                               picks=meg_ica_ecg)\n",
    "            #     for i in range(len(fig)):\n",
    "            #         fname_fig = op.join(out_path, \n",
    "            #                             \"04_r%s_ica_meg_ecg%d.png\" % (run,i))\n",
    "            #         fig[i].savefig(fname_fig)\n",
    "            #         plt.close(fig[i])\n",
    "            \n",
    "        \n",
    "        ###################\n",
    "        \n",
    "        # Remove selected components from the signal  #TODO: @Ling why \"apply\" is done in two different steps?\n",
    "        raw_ica = raw.copy()\n",
    "        ica_meg.apply(raw_ica)\n",
    "        \n",
    "        # Show cleaned signal\n",
    "        fig_ica = raw_ica.plot(order=chan_idxs,\n",
    "                               duration=50,\n",
    "                               start=100)        \n",
    "        fname_fig_ica = op.join(out_path,\n",
    "                                '06_r%s_ica_rawICA.png' % run)\n",
    "        fig_ica.savefig(fname_fig_ica)\n",
    "        plt.close()\n",
    "        \n",
    "        '''\n",
    "        # Add figures to report\n",
    "        pdf.ln(120)\n",
    "        pdf.cell(0, 10, 'Timecourse of output data', 'B', ln=1)\n",
    "        pdf.image(fname_fig_ica, 0, 175, pdf.epw)\n",
    "        '''\n",
    "        # Save cleaned raw data\n",
    "        fname_out = op.join(out_path,\n",
    "                            file_name + '_ica.fif')\n",
    "        raw_ica.save(fname_out,overwrite=True)\n",
    "    \n",
    "    # Save report  #TODO: add note about removed ICs\n",
    "    pdf.output(op.join(out_path,\n",
    "                       'apply_ica' + '-report.pdf'))\n",
    "    \n",
    "    # sys.stdout.close()      # close log file\n",
    "    # sys.stdout = stdout_obj # restore command prompt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load 07-make_epochs.py\n",
    "\"\"\"\n",
    "====================\n",
    "07. Make epochs\n",
    "====================\n",
    "\n",
    "Open issues:\n",
    "    - baseline correction -> removed\n",
    "    - apply (SSP) projections?\n",
    "    - separate MEG and EEG in two different FIF files?\n",
    "    - Exp.2: separate VG and replay in two different files?\n",
    "    - detrand required for EEG data: when do we apply it? to epochs or to events?\n",
    "    - remove peak-to-peak rejection?\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def run_epochs():\n",
    "\n",
    "    # stdout_obj = sys.stdout                 # store original stdout \n",
    "    # sys.stdout = open(op.join(out_path,     # open log file\n",
    "    #                            os.path.basename(__file__) + \"_%s.txt\" % (site_id+subject_id)),'w')\n",
    "    \n",
    "    # Prepare PDF report\n",
    "    pdf = FPDF(orientation=\"P\", unit=\"mm\", format=\"A4\")\n",
    "    \n",
    "    print(\"Processing subject: %s\" % subject_id)\n",
    "    \n",
    "    # Create empty lists\n",
    "    raw_list = list()\n",
    "    events_list = list()\n",
    "    metadata_list = list()\n",
    "    \n",
    "    print(\"Processing subject: %s\" % subject_id)\n",
    "    run = 0\n",
    "    for file_name in file_names:\n",
    "        run = run + 1\n",
    "        print(\"  File: %s\" % file_name)\n",
    "        \n",
    "        # Read raw data\n",
    "        raw_fname_in = op.join(out_path,\n",
    "                               file_name + '_ica.fif')\n",
    "        raw_tmp = mne.io.read_raw_fif(\n",
    "            raw_fname_in, \n",
    "            preload=False, \n",
    "            verbose='error')\n",
    "        \n",
    "        # Read events\n",
    "        events_tmp = mne.read_events(op.join(out_path,\n",
    "                                             file_name + '-eve.fif'))                           \n",
    "        # Read metadata\n",
    "        metadata_tmp = pd.read_csv(op.join(out_path,\n",
    "                                           file_name + '-meta.csv'))\n",
    "        \n",
    "        # Append read data to list\n",
    "        raw_list.append(raw_tmp)\n",
    "        events_list.append(events_tmp)\n",
    "        metadata_list.append(metadata_tmp)\n",
    "\n",
    "    # Concatenate raw instances as if they were continuous\n",
    "    raw, events = mne.concatenate_raws(raw_list,\n",
    "                                       events_list=events_list)\n",
    "    del raw_list\n",
    "    \n",
    "    # Concatenate metadata tables\n",
    "    metadata = pd.concat(metadata_list)\n",
    "    metadata.to_csv(op.join(out_path,\n",
    "                            file_name[0:14] + 'ALL-meta.csv'),\n",
    "                    index=False)\n",
    "    \n",
    "    # Set reject criteria\n",
    "    \n",
    "    reject = reject_meg\n",
    "    \n",
    "    # Select sensor types\n",
    "    picks = mne.pick_types(raw.info,\n",
    "                           meg = True,\n",
    "                           stim = True)\n",
    "    \n",
    "    # Epoch raw data\n",
    "    epochs = mne.Epochs(raw,\n",
    "                        events, \n",
    "                        events_id,\n",
    "                        tmin, tmax,\n",
    "                        baseline=None,\n",
    "                        proj=True,\n",
    "                        picks=picks,\n",
    "                        # detrend=1,\n",
    "                        reject=reject,\n",
    "                        reject_by_annotation=False,\n",
    "                        verbose=True)\n",
    "    \n",
    "    # epochs.metadata = metadata\n",
    "    \n",
    "    del raw\n",
    "    \n",
    "    # Add metadata\n",
    "    epochs.metadata = metadata\n",
    "    \n",
    "    # Drop bad epochs based on peak-to-peak magnitude\n",
    "    epochs.drop_bad()\n",
    "    \n",
    "    # Plot percentage of rejected epochs per channel\n",
    "    fig1 = epochs.plot_drop_log()\n",
    "    fname_fig1 = op.join(out_path,\n",
    "                        '07_rAll_epoch_drop.png')\n",
    "    fig1.savefig(fname_fig1)\n",
    "    plt.close()\n",
    "    \n",
    "    '''\n",
    "    # Add figure to report\n",
    "    pdf.add_page()\n",
    "    pdf.set_font('helvetica', 'B', 16)\n",
    "    pdf.cell(0, 10, file_name)\n",
    "    pdf.ln(20)\n",
    "    pdf.set_font('helvetica', 'B', 12)\n",
    "    pdf.cell(0, 10, 'Percentage of rejected epochs', 'B', ln=1)\n",
    "    pdf.image(fname_fig1, 0, 45, pdf.epw)\n",
    "    '''\n",
    "    # Plot evoked by epoch\n",
    "    fig2 = epochs.plot(picks='meg',\n",
    "                      title='meg',\n",
    "                      n_epochs=10)\n",
    "    fname_fig2 = op.join(out_path,\n",
    "                        '07_rAll_epoch_evk.png')\n",
    "    fig2.savefig(fname_fig2)\n",
    "    plt.close(fig2)\n",
    "    \n",
    "    '''\n",
    "    # Add figures to report\n",
    "    pdf.ln(120)\n",
    "    pdf.cell(0, 10, 'Epoched data', 'B', ln=1)\n",
    "    pdf.image(fname_fig2, 0, 175, pdf.epw)\n",
    "    '''\n",
    "    # Count the number of epochs defined by different events\n",
    "    # Save epoched data\n",
    "    epochs.save(op.join(out_path,\n",
    "                        file_names[0][0:13] + 'ALL_epo.fif'),                           \n",
    "                    overwrite=True)\n",
    "    \n",
    "    # Save report  #TODO: add note about removed ICs\n",
    "    pdf.output(op.join(out_path,\n",
    "                       'run_epochs' + '-report.pdf'))\n",
    "    \n",
    "    # sys.stdout.close()      # close log file\n",
    "    # sys.stdout = stdout_obj # restore command prompt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Manually selected ICs  #TODO: move and read these info from a separate table file\n",
    "# #MEG\n",
    "# meg_ica_eog = [0]\n",
    "# meg_ica_ecg = [18]\n",
    "# #EEG\n",
    "# eeg_ica_eog = [0]\n",
    "# eeg_ica_ecg = [6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load config.py\n",
    "\"\"\"\n",
    "===========\n",
    "Config file\n",
    "===========\n",
    "\n",
    "Configurate the parameters of the study.\n",
    "\"\"\"\n",
    "\n",
    "for subject_id in subject_list[1:]:\n",
    "\n",
    "    # =============================================================================\n",
    "    # SESSION-SPECIFIC SETTINGS\n",
    "    # =============================================================================\n",
    "\n",
    "    # Set filename based on experiment number\n",
    "    file_exts = ['%sa01',\n",
    "                     '%sa02',\n",
    "                     '%sa03',\n",
    "                     '%sa04',\n",
    "                     '%sa05',\n",
    "                     '%sa06',\n",
    "                     '%sb07',\n",
    "                     '%sb08',\n",
    "                     '%sb09',\n",
    "                     '%sb10',\n",
    "                     '%sb11',\n",
    "                     '%sb12']#,\n",
    "\n",
    "    file_names = [f % (subject_id) for f in file_exts]\n",
    "\n",
    "\n",
    "    # =============================================================================\n",
    "    # GENERAL SETTINGS\n",
    "    # =============================================================================\n",
    "\n",
    "    # Set out_path folder or create it if it doesn't exist\n",
    "    out_path = op.join(data_path, \"out_path\")\n",
    "    if not op.exists(out_path):\n",
    "        os.mkdir(out_path)\n",
    "\n",
    "\n",
    "    # =============================================================================\n",
    "    # MAXWELL FILTERING SETTINGS\n",
    "    # =============================================================================\n",
    "\n",
    "    # Set filtering method\n",
    "    method='sss'\n",
    "    if method == 'tsss':\n",
    "        st_duration = 10\n",
    "    else:\n",
    "        st_duration = None\n",
    "\n",
    "\n",
    "    # =============================================================================\n",
    "    # FILTERING AND DOWNSAMPLING SETTINGS\n",
    "    # =============================================================================\n",
    "\n",
    "    # Filter and resampling params\n",
    "    l_freq = 1\n",
    "    h_freq = 40\n",
    "    sfreq = 200\n",
    "\n",
    "\n",
    "    # =============================================================================\n",
    "    # EPOCHING SETTINGS\n",
    "    # =============================================================================\n",
    "\n",
    "    # Set timewindow\n",
    "    tmin = -0.5\n",
    "    tmax = 8.1\n",
    "\n",
    "    # Epoch rejection criteria\n",
    "    reject_meg = dict(grad=4000e-13,    # T / m (gradiometers)\n",
    "                      mag=4e-12         # T (magnetometers)\n",
    "                      )\n",
    "\n",
    "    # Set epoching event ids\n",
    "\n",
    "    events_id = 101\n",
    "\n",
    "\n",
    "\n",
    "    # =============================================================================\n",
    "    # ICA SETTINGS\n",
    "    # =============================================================================\n",
    "\n",
    "    ica_method = 'fastica'\n",
    "    n_components = 0.99\n",
    "    max_iter = 800\n",
    "    random_state = 1688\n",
    "\n",
    "\n",
    "    # =============================================================================\n",
    "    #  FACTOR AND CONDITIONS OF INTEREST\n",
    "    # =============================================================================\n",
    "\n",
    "    \n",
    "    # factor = 'Category'\n",
    "    # conditions = ['face', 'object', 'letter', 'false']\n",
    "\n",
    "        # factor = 'Relevance'\n",
    "        # conditions = ['Relevant target','Relevant non-target','Irrelevant']\n",
    "\n",
    "\n",
    "    # =============================================================================\n",
    "    # TIME-FREQUENCY REPRESENTATION SETTINGS\n",
    "    # =============================================================================\n",
    "\n",
    "    baseline_w = [-0.5, -0.25]     #only for plotting\n",
    "    freq_band = 'both' #can be 'low', 'high' or 'both'\n",
    "\n",
    "    # =============================================================================\n",
    "    # RUN\n",
    "    # =============================================================================\n",
    "\n",
    "    meg_ica_eog,meg_ica_ecg = ica_choice[0],ica_choice[1]\n",
    "    \n",
    "    apply_ica(meg_ica_eog = meg_ica_eog,\n",
    "              meg_ica_ecg = meg_ica_ecg)\n",
    "\n",
    "    run_epochs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'face1': 1, 'face2': 2, 'face3': 3, 'face4': 4, 'face5': 5, 'face6': 6, 'face7': 7, 'face8': 8, 'face9': 9, 'face10': 10, 'face11': 11, 'face12': 12, 'face13': 13, 'face14': 14, 'face15': 15, 'face16': 16, 'face17': 17, 'face18': 18, 'face19': 19, 'face20': 20, 'object1': 21, 'object2': 22, 'object3': 23, 'object4': 24, 'object5': 25, 'object6': 26, 'object7': 27, 'object8': 28, 'object9': 29, 'object10': 30, 'object11': 31, 'object12': 32, 'object13': 33, 'object14': 34, 'object15': 35, 'object16': 36, 'object17': 37, 'object18': 38, 'object19': 39, 'object20': 40, 'letter1': 41, 'letter2': 42, 'letter3': 43, 'letter4': 44, 'letter5': 45, 'letter6': 46, 'letter7': 47, 'letter8': 48, 'letter9': 49, 'letter10': 50, 'letter11': 51, 'letter12': 52, 'letter13': 53, 'letter14': 54, 'letter15': 55, 'letter16': 56, 'letter17': 57, 'letter18': 58, 'letter19': 59, 'letter20': 60, 'false1': 61, 'false2': 62, 'false3': 63, 'false4': 64, 'false5': 65, 'false6': 66, 'false7': 67, 'false8': 68, 'false9': 69, 'false10': 70, 'false11': 71, 'false12': 72, 'false13': 73, 'false14': 74, 'false15': 75, 'false16': 76, 'false17': 77, 'false18': 78, 'false19': 79, 'false20': 80}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name='mg99a01'\n",
    "data_path =  'D:\\projects\\WM_GRID\\DATA\\mg99a'\n",
    "raw_fname_in = op.join(data_path,\n",
    "                        file_name + '.fif')\n",
    "raw = mne.io.read_raw_fif(\n",
    "            raw_fname_in, \n",
    "            preload=True, \n",
    "            verbose='error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.info['dev_head_t'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name='mg99a01'\n",
    "data_path =  'D:\\projects\\WM_GRID\\DATA\\mg99a'\n",
    "out_path = op.join(data_path, \"out_path\")\n",
    "raw_fname_in = op.join(out_path,\n",
    "                        file_name + '_sss.fif')\n",
    "raw = mne.io.read_raw_fif(\n",
    "            raw_fname_in, \n",
    "            preload=True, \n",
    "            verbose='error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.info['dev_head_t'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name='mg99a02'\n",
    "data_path =  'D:\\projects\\WM_GRID\\DATA\\mg99a'\n",
    "out_path = op.join(data_path)\n",
    "raw_fname_in = op.join(out_path,\n",
    "                        file_name + '.fif')\n",
    "raw = mne.io.read_raw_fif(\n",
    "            raw_fname_in, \n",
    "            preload=True, \n",
    "            verbose='error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.info['dev_head_t'] "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
